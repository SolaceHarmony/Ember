{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "class MetronomeTime:\n",
    "    def __init__(self, tick_rate=0.01):\n",
    "        self.current_tick = 0\n",
    "        self.tick_rate = tick_rate\n",
    "        self.lobe_states = {}\n",
    "        \n",
    "    def register_lobe(self, lobe_id):\n",
    "        self.lobe_states[lobe_id] = False\n",
    "        \n",
    "    def tick(self):\n",
    "        if all(self.lobe_states.values()):\n",
    "            self.current_tick += self.tick_rate\n",
    "            self.lobe_states = {k: False for k in self.lobe_states}\n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def save_state(self, path):\n",
    "        state = {\n",
    "            'current_tick': self.current_tick,\n",
    "            'tick_rate': self.tick_rate\n",
    "        }\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(state, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Harmonic Embeddings\n",
    "class HarmonicEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_harmonics):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_harmonics = num_harmonics\n",
    "        self.frequencies = nn.Parameter(torch.randn(num_harmonics))\n",
    "        self.phases = nn.Parameter(torch.randn(num_harmonics))\n",
    "        \n",
    "    def forward(self, t):\n",
    "        # Generate harmonic basis\n",
    "        t = t.unsqueeze(-1)\n",
    "        harmonics = torch.sin(2 * np.pi * self.frequencies * t + self.phases)\n",
    "        return harmonics\n",
    "    \n",
    "    def save_embeddings(self, path):\n",
    "        state = {\n",
    "            'frequencies': self.frequencies.detach().cpu().numpy(),\n",
    "            'phases': self.phases.detach().cpu().numpy()\n",
    "        }\n",
    "        torch.save(state, path)\n",
    "        \n",
    "    def load_embeddings(self, path):\n",
    "        state = torch.load(path)\n",
    "        self.frequencies.data = torch.tensor(state['frequencies'])\n",
    "        self.phases.data = torch.tensor(state['phases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: LTC Neuron with Persistence\n",
    "from typing import Tuple, Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class LiquidTimeConstant(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Backbone network\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Linear(input_size + hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size)\n",
    "        )\n",
    "        \n",
    "        # Networks for liquid time-constant mechanism\n",
    "        self.time_net = nn.Linear(hidden_size, hidden_size)\n",
    "        self.state_net_g = nn.Linear(hidden_size, hidden_size)\n",
    "        self.state_net_h = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        # Learnable parameters\n",
    "        self.tau = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.A = nn.Parameter(torch.randn(hidden_size))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, h: torch.Tensor, t: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Create new tensor instead of modifying in place\n",
    "        h_new = h.clone()\n",
    "        \n",
    "        # Combine inputs using non-inplace operations\n",
    "        combined = torch.cat([x, h_new], dim=-1)\n",
    "        features = self.backbone(combined)\n",
    "        \n",
    "        # Compute time-constant factor\n",
    "        f_t = torch.sigmoid(self.time_net(features))\n",
    "        \n",
    "        # State transformations\n",
    "        g_x = self.state_net_g(features)\n",
    "        h_x = self.state_net_h(features)\n",
    "        \n",
    "        # Time-dependent gating using non-inplace operations\n",
    "        t_view = t.view(-1, 1)\n",
    "        gate = torch.sigmoid(torch.mul(-f_t, t_view))\n",
    "        \n",
    "        # Create new tensors for intermediate computations\n",
    "        gate_g = torch.mul(gate, g_x)\n",
    "        inverse_gate = torch.sub(torch.ones_like(gate), gate)\n",
    "        gate_h = torch.mul(inverse_gate, h_x)\n",
    "        \n",
    "        # Combine outputs into new tensor\n",
    "        output = torch.add(gate_g, gate_h)\n",
    "        \n",
    "        return output, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerLNN(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_heads: int = 4, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        # Layers\n",
    "        self.input_proj = nn.Linear(input_size, hidden_size)\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout)\n",
    "        self.ltc = LiquidTimeConstant(hidden_size, hidden_size)\n",
    "        self.output_proj = nn.Linear(hidden_size, input_size)\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.norm1 = nn.LayerNorm(hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(hidden_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, times: Optional[torch.Tensor] = None, \n",
    "                mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        if times is None:\n",
    "            times = torch.arange(seq_len, dtype=torch.float32, device=x.device)\n",
    "            times = times.unsqueeze(0).expand(batch_size, -1)\n",
    "        \n",
    "        # Project input\n",
    "        h = self.input_proj(x)\n",
    "        \n",
    "        # Self-attention\n",
    "        h_att = h.transpose(0, 1)\n",
    "        h_att, _ = self.attention(h_att, h_att, h_att, attn_mask=mask)\n",
    "        h_att = h_att.transpose(0, 1)\n",
    "        h_att = self.norm1(h + h_att)\n",
    "        \n",
    "        # LTC processing\n",
    "        ltc_state = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        outputs = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            ltc_in = h_att[:, t]\n",
    "            ltc_out, ltc_state = self.ltc(ltc_in, ltc_state, times[:, t])\n",
    "            outputs.append(ltc_out)\n",
    "        \n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        outputs = self.norm2(outputs + h_att)\n",
    "        \n",
    "        return self.output_proj(outputs)\n",
    "\n",
    "    def get_attention_weights(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h = self.input_proj(x)\n",
    "        h = h.transpose(0, 1)\n",
    "        _, attn_weights = self.attention(h, h, h, need_weights=True)\n",
    "        return attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersistentLTCNeuron(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.ltc = LiquidTimeConstant(input_size, hidden_size)\n",
    "        self.state_history = []\n",
    "        self.lobe_id = None\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, h: torch.Tensor, t: torch.Tensor, metronome: MetronomeTime):\n",
    "        if self.lobe_id is not None:\n",
    "            metronome.lobe_states[self.lobe_id] = True\n",
    "        \n",
    "        # Forward pass through LTC with proper arguments\n",
    "        output, new_state = self.ltc(x, h, t)\n",
    "        \n",
    "        # Record state history\n",
    "        self.state_history.append({\n",
    "            'time': metronome.current_tick,\n",
    "            'state': new_state.detach().cpu().numpy()\n",
    "        })\n",
    "        \n",
    "        return output, new_state\n",
    "        \n",
    "    def save_state(self, path):\n",
    "        state = {\n",
    "            'model_state': self.ltc.state_dict(),\n",
    "            'history': self.state_history\n",
    "        }\n",
    "        torch.save(state, path)\n",
    "        \n",
    "    def load_state(self, path):\n",
    "        state = torch.load(path)\n",
    "        self.ltc.load_state_dict(state['model_state'])\n",
    "        self.state_history = state['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridEmbeddingLayer(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, num_harmonics: int):\n",
    "        super().__init__()\n",
    "        self.transformer_embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.harmonic_embedding = HarmonicEmbedding(embedding_dim, num_harmonics)\n",
    "        self.phase = \"transformer\"  # Controls training phase\n",
    "        self.embedding_memory = []\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        if self.phase == \"learning\":\n",
    "            # Collect transformer embeddings during initial phase\n",
    "            trans_emb = self.transformer_embedding(x)\n",
    "            self.embedding_memory.append(trans_emb.detach())\n",
    "            return trans_emb\n",
    "            \n",
    "        elif self.phase == \"transition\":\n",
    "            # Use both embeddings and train harmonic LTC\n",
    "            trans_emb = self.transformer_embedding(x)\n",
    "            harm_emb = self.harmonic_embedding(t)\n",
    "            return trans_emb + 0.5 * harm_emb\n",
    "            \n",
    "        else:  # harmonic phase\n",
    "            return self.harmonic_embedding(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LTCEmbeddingChain(nn.Module):\n",
    "    def __init__(self, hidden_size: int, chain_length: int):\n",
    "        super().__init__()\n",
    "        self.ltc_chain = nn.ModuleList([\n",
    "            LiquidTimeConstant(hidden_size, hidden_size) \n",
    "            for _ in range(chain_length)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        h = torch.zeros_like(x)\n",
    "        for ltc in self.ltc_chain:\n",
    "            x, h = ltc(x, h, t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training(t, y_true, y_pred, losses, times, harmonic_embedding):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    # Plot 1: Training Loss\n",
    "    plt.subplot(231)\n",
    "    plt.plot(times, losses)\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Metronome Time')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot 2: Predictions\n",
    "    plt.subplot(232)\n",
    "    plt.plot(t.detach().cpu(), y_true.detach().cpu(), label='True')\n",
    "    plt.plot(t.detach().cpu(), y_pred.detach().cpu(), label='Predicted')\n",
    "    plt.title('Predictions vs Ground Truth')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot 3: Harmonic Components\n",
    "    plt.subplot(233)\n",
    "    with torch.no_grad():\n",
    "        harmonics = harmonic_embedding(t)\n",
    "        harmonics = harmonics.detach().cpu()\n",
    "    plt.plot(t.detach().cpu(), harmonics)\n",
    "    plt.title('Harmonic Components')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_training(input_size=10, hidden_size=64, num_heads=4, \n",
    "                  batch_size=32, learning_rate=1e-3):\n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Initialize model\n",
    "    model = TransformerLNN(\n",
    "        input_size=input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        num_heads=num_heads\n",
    "    ).to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return model, criterion, optimizer, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(num_samples: int = 1000,\n",
    "                          seq_length: int = 50,\n",
    "                          input_dim: int = 10,\n",
    "                          device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "                          ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    t = torch.linspace(0, 10, seq_length, device=device)\n",
    "    t = t.view(1, -1, 1).repeat(num_samples, 1, input_dim)\n",
    "    \n",
    "    patterns = []\n",
    "    for i in range(input_dim):\n",
    "        freq1 = (i + 1) * 0.5\n",
    "        freq2 = (i + 1) * 0.25\n",
    "        pattern = torch.sin(2 * np.pi * freq1 * t[..., i]) + \\\n",
    "                 0.5 * torch.sin(2 * np.pi * freq2 * t[..., i])\n",
    "        patterns.append(pattern)\n",
    "    \n",
    "    x = torch.stack(patterns, dim=-1)\n",
    "    y = torch.roll(x, shifts=-1, dims=1) * 1.5 + 0.5\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ltc_with_harmonics(ltc_neuron, harmonic_embedding, metronome, num_epochs=100, plot_interval=10):\n",
    "    optimizer = optim.Adam(list(ltc_neuron.parameters()) + \n",
    "                          list(harmonic_embedding.parameters()))\n",
    "    \n",
    "    data_logger = DataLogger()\n",
    "    losses = []\n",
    "    times = []\n",
    "    \n",
    "    # Initialize hidden state\n",
    "    batch_size = 32\n",
    "    h = torch.zeros(batch_size, ltc_neuron.ltc.hidden_size)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Generate time steps\n",
    "        t = torch.linspace(0, 10, batch_size)\n",
    "        \n",
    "        # Forward pass through harmonic embedding\n",
    "        x = harmonic_embedding(t)\n",
    "        \n",
    "        # Create new hidden state for each forward pass\n",
    "        h_current = h.clone().detach()\n",
    "        \n",
    "        # Forward pass through LTC\n",
    "        y_pred, new_h = ltc_neuron(x, h_current, t, metronome)\n",
    "        y_true = torch.sin(t).view(-1, 1)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = nn.MSELoss()(y_pred, y_true)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update hidden state after backward pass\n",
    "        h = new_h.detach()\n",
    "        \n",
    "        # Log metrics\n",
    "        data_logger.update_metrics(\n",
    "            epoch=epoch,\n",
    "            batch=0,\n",
    "            loss=loss.item(),\n",
    "            y_pred=y_pred,\n",
    "            y_true=y_true,\n",
    "            ltc_state=h,\n",
    "            attn_weights=torch.zeros(1)  # Placeholder for attention weights\n",
    "        )\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        times.append(metronome.current_tick)\n",
    "        \n",
    "        if epoch % plot_interval == 0:\n",
    "            data_logger.display_recent_metrics()\n",
    "            metronome.tick()\n",
    "    \n",
    "    return losses, times\n",
    "\n",
    "class DataLogger:\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            'epoch': [],\n",
    "            'batch': [],\n",
    "            'loss': [],\n",
    "            'accuracy': [],\n",
    "            'ltc_state_norm': [],\n",
    "            'timestamp': []\n",
    "        }\n",
    "    \n",
    "    def update_metrics(self, epoch, batch, loss, y_pred, y_true, ltc_state, attn_weights):\n",
    "        mse = ((y_pred - y_true) ** 2).mean().item()\n",
    "        accuracy = 100 * (1 - min(mse, 1))\n",
    "        \n",
    "        self.metrics['epoch'].append(epoch)\n",
    "        self.metrics['batch'].append(batch)\n",
    "        self.metrics['loss'].append(f\"{loss:.6f}\")\n",
    "        self.metrics['accuracy'].append(f\"{accuracy:.2f}\")\n",
    "        self.metrics['ltc_state_norm'].append(f\"{torch.norm(ltc_state).item():.4f}\")\n",
    "        self.metrics['timestamp'].append(datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    def display_recent_metrics(self, n_rows: int = 10):\n",
    "        headers = ['Epoch', 'Batch', 'Loss', 'Acc(%)', 'LTC Norm', 'Time']\n",
    "        \n",
    "        data = [\n",
    "            [self.metrics[k][-i] for k in self.metrics.keys()]\n",
    "            for i in range(min(n_rows, len(self.metrics['epoch'])), 0, -1)\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nRecent Training Metrics:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{headers[0]:<6} {headers[1]:<6} {headers[2]:<10} {headers[3]:<8} \"\n",
    "              f\"{headers[4]:<10} {headers[5]:<8}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for row in data:\n",
    "            print(f\"{row[0]:<6} {row[1]:<6} {row[2]:<10} {row[3]:<8} \"\n",
    "                  f\"{row[4]:<10} {row[5]:<8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/stuff/solace/Kognitive/python_proofs/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "0      0      0.476642   52.34    4.1856     20:26:16\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "1      0      0.473311   52.67    4.1262     20:26:16\n",
      "2      0      0.469977   53.00    4.0472     20:26:16\n",
      "3      0      0.466469   53.35    3.9614     20:26:16\n",
      "4      0      0.462935   53.71    3.8926     20:26:17\n",
      "5      0      0.459334   54.07    3.8371     20:26:17\n",
      "6      0      0.455643   54.44    3.7953     20:26:17\n",
      "7      0      0.451836   54.82    3.7674     20:26:17\n",
      "8      0      0.447881   55.21    3.7536     20:26:17\n",
      "9      0      0.443747   55.63    3.7542     20:26:17\n",
      "10     0      0.439396   56.06    3.7699     20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "11     0      0.434787   56.52    3.8013     20:26:17\n",
      "12     0      0.429876   57.01    3.8496     20:26:17\n",
      "13     0      0.424613   57.54    3.9162     20:26:17\n",
      "14     0      0.418940   58.11    4.0031     20:26:17\n",
      "15     0      0.412792   58.72    4.1129     20:26:17\n",
      "16     0      0.406093   59.39    4.2486     20:26:17\n",
      "17     0      0.398756   60.12    4.4147     20:26:17\n",
      "18     0      0.390677   60.93    4.6163     20:26:17\n",
      "19     0      0.381735   61.83    4.8605     20:26:17\n",
      "20     0      0.371784   62.82    5.1561     20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "21     0      0.360649   63.94    5.5147     20:26:17\n",
      "22     0      0.348123   65.19    5.9516     20:26:17\n",
      "23     0      0.333961   66.60    6.4868     20:26:17\n",
      "24     0      0.317895   68.21    7.1467     20:26:17\n",
      "25     0      0.299670   70.03    7.9672     20:26:17\n",
      "26     0      0.279134   72.09    8.9958     20:26:17\n",
      "27     0      0.256444   74.36    10.2951    20:26:17\n",
      "28     0      0.232475   76.75    11.9434    20:26:17\n",
      "29     0      0.209522   79.05    14.0282    20:26:17\n",
      "30     0      0.192177   80.78    16.6124    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "31     0      0.187148   81.29    19.6378    20:26:17\n",
      "32     0      0.198872   80.11    22.7745    20:26:17\n",
      "33     0      0.221541   77.85    25.4411    20:26:17\n",
      "34     0      0.239150   76.09    27.1072    20:26:17\n",
      "35     0      0.237270   76.27    27.5375    20:26:17\n",
      "36     0      0.212930   78.71    26.7898    20:26:17\n",
      "37     0      0.174093   82.59    25.0875    20:26:17\n",
      "38     0      0.133670   86.63    22.7230    20:26:17\n",
      "39     0      0.103600   89.64    20.0254    20:26:17\n",
      "40     0      0.090441   90.96    17.3432    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "41     0      0.093439   90.66    14.9958    20:26:17\n",
      "42     0      0.106265   89.37    13.1970    20:26:17\n",
      "43     0      0.121252   87.87    12.0097    20:26:17\n",
      "44     0      0.132810   86.72    11.3754    20:26:17\n",
      "45     0      0.138272   86.17    11.1900    20:26:17\n",
      "46     0      0.137066   86.29    11.3643    20:26:17\n",
      "47     0      0.129666   87.03    11.8472    20:26:17\n",
      "48     0      0.117006   88.30    12.6233    20:26:17\n",
      "49     0      0.100376   89.96    13.7040    20:26:17\n",
      "50     0      0.081665   91.83    15.1168    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "51     0      0.063788   93.62    16.8915    20:26:17\n",
      "52     0      0.051016   94.90    19.0361    20:26:17\n",
      "53     0      0.048610   95.14    21.4980    20:26:17\n",
      "54     0      0.060727   93.93    24.1084    20:26:17\n",
      "55     0      0.086224   91.38    26.5423    20:26:17\n",
      "56     0      0.115305   88.47    28.3639    20:26:17\n",
      "57     0      0.133120   86.69    29.1948    20:26:17\n",
      "58     0      0.130015   87.00    28.8847    20:26:17\n",
      "59     0      0.108138   89.19    27.5408    20:26:17\n",
      "60     0      0.078429   92.16    25.4400    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "61     0      0.053065   94.69    22.9284    20:26:17\n",
      "62     0      0.039792   96.02    20.3557    20:26:17\n",
      "63     0      0.040042   96.00    18.0259    20:26:17\n",
      "64     0      0.050215   94.98    16.1509    20:26:17\n",
      "65     0      0.064625   93.54    14.8188    20:26:17\n",
      "66     0      0.078233   92.18    14.0056    20:26:17\n",
      "67     0      0.087982   91.20    13.6258    20:26:17\n",
      "68     0      0.092742   90.73    13.5871    20:26:17\n",
      "69     0      0.092648   90.74    13.8200    20:26:17\n",
      "70     0      0.088459   91.15    14.2819    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "71     0      0.081209   91.88    14.9511    20:26:17\n",
      "72     0      0.072097   92.79    15.8179    20:26:17\n",
      "73     0      0.062510   93.75    16.8767    20:26:17\n",
      "74     0      0.054055   94.59    18.1184    20:26:17\n",
      "75     0      0.048504   95.15    19.5206    20:26:17\n",
      "76     0      0.047531   95.25    21.0372    20:26:17\n",
      "77     0      0.052168   94.78    22.5880    20:26:17\n",
      "78     0      0.062032   93.80    24.0524    20:26:17\n",
      "79     0      0.074638   92.54    25.2727    20:26:17\n",
      "80     0      0.085541   91.45    26.0784    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "81     0      0.090004   91.00    26.3314    20:26:17\n",
      "82     0      0.085600   91.44    25.9753    20:26:17\n",
      "83     0      0.073671   92.63    25.0559    20:26:17\n",
      "84     0      0.058426   94.16    23.7049    20:26:17\n",
      "85     0      0.044651   95.53    22.1029    20:26:17\n",
      "86     0      0.035670   96.43    20.4421    20:26:17\n",
      "87     0      0.032476   96.75    18.8945    20:26:17\n",
      "88     0      0.034058   96.59    17.5898    20:26:17\n",
      "89     0      0.038376   96.16    16.6056    20:26:17\n",
      "90     0      0.043311   95.67    15.9714    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "91     0      0.047189   95.28    15.6803    20:26:17\n",
      "92     0      0.048939   95.11    15.7048    20:26:17\n",
      "93     0      0.048067   95.19    16.0104    20:26:17\n",
      "94     0      0.044610   95.54    16.5645    20:26:17\n",
      "95     0      0.039100   96.09    17.3393    20:26:17\n",
      "96     0      0.032522   96.75    18.3099    20:26:17\n",
      "97     0      0.026251   97.37    19.4489    20:26:17\n",
      "98     0      0.021917   97.81    20.7192    20:26:17\n",
      "99     0      0.021142   97.89    22.0656    20:26:17\n",
      "100    0      0.025058   97.49    23.4070    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "101    0      0.033609   96.64    24.6309    20:26:17\n",
      "102    0      0.044899   95.51    25.5988    20:26:17\n",
      "103    0      0.055194   94.48    26.1655    20:26:17\n",
      "104    0      0.060345   93.97    26.2188    20:26:17\n",
      "105    0      0.058310   94.17    25.7254    20:26:17\n",
      "106    0      0.050531   94.95    24.7511    20:26:17\n",
      "107    0      0.040764   95.92    23.4385    20:26:17\n",
      "108    0      0.032677   96.73    21.9627    20:26:17\n",
      "109    0      0.028198   97.18    20.4911    20:26:17\n",
      "110    0      0.027329   97.27    19.1588    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "111    0      0.028911   97.11    18.0601    20:26:17\n",
      "112    0      0.031515   96.85    17.2501    20:26:17\n",
      "113    0      0.033992   96.60    16.7509    20:26:17\n",
      "114    0      0.035637   96.44    16.5602    20:26:17\n",
      "115    0      0.036143   96.39    16.6601    20:26:17\n",
      "116    0      0.035487   96.45    17.0237    20:26:17\n",
      "117    0      0.033867   96.61    17.6197    20:26:17\n",
      "118    0      0.031678   96.83    18.4134    20:26:17\n",
      "119    0      0.029478   97.05    19.3647    20:26:17\n",
      "120    0      0.027907   97.21    20.4252    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "121    0      0.027512   97.25    21.5340    20:26:17\n",
      "122    0      0.028534   97.15    22.6164    20:26:17\n",
      "123    0      0.030696   96.93    23.5847    20:26:17\n",
      "124    0      0.033146   96.69    24.3455    20:26:17\n",
      "125    0      0.034711   96.53    24.8145    20:26:17\n",
      "126    0      0.034528   96.55    24.9368    20:26:17\n",
      "127    0      0.032727   96.73    24.7048    20:26:17\n",
      "128    0      0.030447   96.96    24.1589    20:26:17\n",
      "129    0      0.029008   97.10    23.3693    20:26:17\n",
      "130    0      0.029197   97.08    22.4215    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "131    0      0.031223   96.88    21.4103    20:26:17\n",
      "132    0      0.034679   96.53    20.4281    20:26:17\n",
      "133    0      0.038540   96.15    19.5471    20:26:17\n",
      "134    0      0.041577   95.84    18.8144    20:26:17\n",
      "135    0      0.042835   95.72    18.2574    20:26:17\n",
      "136    0      0.041837   95.82    17.8903    20:26:17\n",
      "137    0      0.038570   96.14    17.7197    20:26:17\n",
      "138    0      0.033402   96.66    17.7482    20:26:17\n",
      "139    0      0.026987   97.30    17.9766    20:26:17\n",
      "140    0      0.020206   97.98    18.4041    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "141    0      0.014120   98.59    19.0259    20:26:17\n",
      "142    0      0.009913   99.01    19.8289    20:26:17\n",
      "143    0      0.008763   99.12    20.7852    20:26:17\n",
      "144    0      0.011553   98.84    21.8448    20:26:17\n",
      "145    0      0.018448   98.16    22.9287    20:26:17\n",
      "146    0      0.028443   97.16    23.9285    20:26:17\n",
      "147    0      0.039217   96.08    24.7167    20:26:17\n",
      "148    0      0.047635   95.24    25.1688    20:26:17\n",
      "149    0      0.050942   94.91    25.1950    20:26:17\n",
      "150    0      0.048083   95.19    24.7680    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "151    0      0.040272   95.97    23.9343    20:26:17\n",
      "152    0      0.030411   96.96    22.8068    20:26:17\n",
      "153    0      0.021727   97.83    21.5401    20:26:17\n",
      "154    0      0.016474   98.35    20.2982    20:26:17\n",
      "155    0      0.015318   98.47    19.2225    20:26:17\n",
      "156    0      0.017519   98.25    18.4091    20:26:17\n",
      "157    0      0.021579   97.84    17.9016    20:26:17\n",
      "158    0      0.025934   97.41    17.7005    20:26:17\n",
      "159    0      0.029427   97.06    17.7813    20:26:17\n",
      "160    0      0.031475   96.85    18.1089    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "161    0      0.032024   96.80    18.6456    20:26:17\n",
      "162    0      0.031406   96.86    19.3505    20:26:17\n",
      "163    0      0.030162   96.98    20.1771    20:26:17\n",
      "164    0      0.028834   97.12    21.0698    20:26:17\n",
      "165    0      0.027754   97.22    21.9616    20:26:17\n",
      "166    0      0.026887   97.31    22.7759    20:26:17\n",
      "167    0      0.025823   97.42    23.4342    20:26:17\n",
      "168    0      0.024007   97.60    23.8676    20:26:17\n",
      "169    0      0.021134   97.89    24.0317    20:26:17\n",
      "170    0      0.017450   98.26    23.9157    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "171    0      0.013750   98.62    23.5442    20:26:17\n",
      "172    0      0.011125   98.89    22.9743    20:26:17\n",
      "173    0      0.010613   98.94    22.2872    20:26:17\n",
      "174    0      0.012773   98.72    21.5727    20:26:17\n",
      "175    0      0.017350   98.26    20.9092    20:26:17\n",
      "176    0      0.023321   97.67    20.3496    20:26:17\n",
      "177    0      0.029290   97.07    19.9194    20:26:17\n",
      "178    0      0.033968   96.60    19.6236    20:26:17\n",
      "179    0      0.036499   96.35    19.4561    20:26:17\n",
      "180    0      0.036550   96.34    19.4076    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "181    0      0.034237   96.58    19.4695    20:26:17\n",
      "182    0      0.029995   97.00    19.6347    20:26:17\n",
      "183    0      0.024468   97.55    19.8972    20:26:17\n",
      "184    0      0.018433   98.16    20.2507    20:26:17\n",
      "185    0      0.012734   98.73    20.6858    20:26:17\n",
      "186    0      0.008205   99.18    21.1877    20:26:17\n",
      "187    0      0.005574   99.44    21.7332    20:26:17\n",
      "188    0      0.005328   99.47    22.2887    20:26:17\n",
      "189    0      0.007548   99.25    22.8090    20:26:17\n",
      "190    0      0.011752   98.82    23.2382    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "191    0      0.016916   98.31    23.5157    20:26:17\n",
      "192    0      0.021806   97.82    23.5903    20:26:17\n",
      "193    0      0.025436   97.46    23.4345    20:26:17\n",
      "194    0      0.027367   97.26    23.0528    20:26:17\n",
      "195    0      0.027708   97.23    22.4821    20:26:17\n",
      "196    0      0.026908   97.31    21.7851    20:26:17\n",
      "197    0      0.025473   97.45    21.0397    20:26:17\n",
      "198    0      0.023746   97.63    20.3263    20:26:17\n",
      "199    0      0.021833   97.82    19.7168    20:26:17\n",
      "200    0      0.019673   98.03    19.2674    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "201    0      0.017180   98.28    19.0158    20:26:17\n",
      "202    0      0.014367   98.56    18.9819    20:26:17\n",
      "203    0      0.011435   98.86    19.1702    20:26:17\n",
      "204    0      0.008790   99.12    19.5717    20:26:17\n",
      "205    0      0.007005   99.30    20.1634    20:26:17\n",
      "206    0      0.006701   99.33    20.9070    20:26:17\n",
      "207    0      0.008345   99.17    21.7449    20:26:17\n",
      "208    0      0.011978   98.80    22.5990    20:26:17\n",
      "209    0      0.016981   98.30    23.3726    20:26:17\n",
      "210    0      0.022055   97.79    23.9607    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "211    0      0.025585   97.44    24.2685    20:26:17\n",
      "212    0      0.026320   97.37    24.2341    20:26:17\n",
      "213    0      0.024032   97.60    23.8476    20:26:17\n",
      "214    0      0.019687   98.03    23.1577    20:26:17\n",
      "215    0      0.014967   98.50    22.2635    20:26:17\n",
      "216    0      0.011427   98.86    21.2925    20:26:17\n",
      "217    0      0.009832   99.02    20.3733    20:26:17\n",
      "218    0      0.010007   99.00    19.6123    20:26:17\n",
      "219    0      0.011166   98.88    19.0806    20:26:17\n",
      "220    0      0.012405   98.76    18.8133    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "221    0      0.013086   98.69    18.8168    20:26:17\n",
      "222    0      0.013003   98.70    19.0779    20:26:17\n",
      "223    0      0.012371   98.76    19.5697    20:26:17\n",
      "224    0      0.011706   98.83    20.2533    20:26:17\n",
      "225    0      0.011626   98.84    21.0752    20:26:17\n",
      "226    0      0.012585   98.74    21.9642    20:26:17\n",
      "227    0      0.014585   98.54    22.8300    20:26:17\n",
      "228    0      0.017007   98.30    23.5682    20:26:17\n",
      "229    0      0.018726   98.13    24.0750    20:26:17\n",
      "230    0      0.018618   98.14    24.2684    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "231    0      0.016242   98.38    24.1112    20:26:17\n",
      "232    0      0.012233   98.78    23.6243    20:26:17\n",
      "233    0      0.008069   99.19    22.8852    20:26:17\n",
      "234    0      0.005308   99.47    22.0090    20:26:17\n",
      "235    0      0.004815   99.52    21.1221    20:26:17\n",
      "236    0      0.006460   99.35    20.3356    20:26:17\n",
      "237    0      0.009359   99.06    19.7296    20:26:17\n",
      "238    0      0.012389   98.76    19.3484    20:26:17\n",
      "239    0      0.014635   98.54    19.2061    20:26:17\n",
      "240    0      0.015620   98.44    19.2958    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "241    0      0.015318   98.47    19.5966    20:26:17\n",
      "242    0      0.014062   98.59    20.0778    20:26:17\n",
      "243    0      0.012390   98.76    20.6994    20:26:17\n",
      "244    0      0.010871   98.91    21.4103    20:26:17\n",
      "245    0      0.009920   99.01    22.1472    20:26:17\n",
      "246    0      0.009638   99.04    22.8353    20:26:17\n",
      "247    0      0.009752   99.02    23.3947    20:26:17\n",
      "248    0      0.009744   99.03    23.7513    20:26:17\n",
      "249    0      0.009151   99.08    23.8519    20:26:17\n",
      "250    0      0.007902   99.21    23.6785    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "251    0      0.006446   99.36    23.2557    20:26:17\n",
      "252    0      0.005532   99.45    22.6462    20:26:17\n",
      "253    0      0.005773   99.42    21.9371    20:26:17\n",
      "254    0      0.007296   99.27    21.2220    20:26:17\n",
      "255    0      0.009683   99.03    20.5837    20:26:17\n",
      "256    0      0.012181   98.78    20.0843    20:26:17\n",
      "257    0      0.014022   98.60    19.7617    20:26:17\n",
      "258    0      0.014685   98.53    19.6329    20:26:17\n",
      "259    0      0.014002   98.60    19.6987    20:26:17\n",
      "260    0      0.012163   98.78    19.9476    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "261    0      0.009630   99.04    20.3582    20:26:17\n",
      "262    0      0.007024   99.30    20.8991    20:26:17\n",
      "263    0      0.004980   99.50    21.5271    20:26:17\n",
      "264    0      0.003973   99.60    22.1865    20:26:17\n",
      "265    0      0.004166   99.58    22.8097    20:26:17\n",
      "266    0      0.005323   99.47    23.3225    20:26:17\n",
      "267    0      0.006880   99.31    23.6539    20:26:17\n",
      "268    0      0.008192   99.18    23.7499    20:26:17\n",
      "269    0      0.008857   99.11    23.5873    20:26:17\n",
      "270    0      0.008912   99.11    23.1818    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "271    0      0.008763   99.12    22.5872    20:26:17\n",
      "272    0      0.008882   99.11    21.8846    20:26:17\n",
      "273    0      0.009487   99.05    21.1663    20:26:17\n",
      "274    0      0.010412   98.96    20.5184    20:26:17\n",
      "275    0      0.011215   98.88    20.0095    20:26:17\n",
      "276    0      0.011415   98.86    19.6858    20:26:17\n",
      "277    0      0.010709   98.93    19.5714    20:26:17\n",
      "278    0      0.009087   99.09    19.6726    20:26:17\n",
      "279    0      0.006853   99.31    19.9808    20:26:17\n",
      "280    0      0.004561   99.54    20.4737    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "281    0      0.002891   99.71    21.1142    20:26:17\n",
      "282    0      0.002455   99.75    21.8476    20:26:17\n",
      "283    0      0.003554   99.64    22.5997    20:26:17\n",
      "284    0      0.005947   99.41    23.2786    20:26:17\n",
      "285    0      0.008817   99.12    23.7853    20:26:17\n",
      "286    0      0.011033   98.90    24.0305    20:26:17\n",
      "287    0      0.011709   98.83    23.9584    20:26:17\n",
      "288    0      0.010727   98.93    23.5649    20:26:17\n",
      "289    0      0.008819   99.12    22.9041    20:26:17\n",
      "290    0      0.007104   99.29    22.0772    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "291    0      0.006403   99.36    21.2087    20:26:17\n",
      "292    0      0.006824   99.32    20.4183    20:26:17\n",
      "293    0      0.007839   99.22    19.8001    20:26:17\n",
      "294    0      0.008682   99.13    19.4138    20:26:17\n",
      "295    0      0.008756   99.12    19.2866    20:26:17\n",
      "296    0      0.007867   99.21    19.4205    20:26:17\n",
      "297    0      0.006261   99.37    19.7990    20:26:17\n",
      "298    0      0.004534   99.55    20.3901    20:26:17\n",
      "299    0      0.003447   99.66    21.1452    20:26:17\n",
      "300    0      0.003654   99.63    21.9950    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "301    0      0.005381   99.46    22.8473    20:26:17\n",
      "302    0      0.008156   99.18    23.5907    20:26:17\n",
      "303    0      0.010843   98.92    24.1084    20:26:17\n",
      "304    0      0.012118   98.79    24.3028    20:26:17\n",
      "305    0      0.011247   98.88    24.1236    20:26:17\n",
      "306    0      0.008635   99.14    23.5878    20:26:17\n",
      "307    0      0.005650   99.44    22.7802    20:26:17\n",
      "308    0      0.003784   99.62    21.8332    20:26:17\n",
      "309    0      0.003782   99.62    20.8931    20:26:17\n",
      "310    0      0.005339   99.47    20.0877    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "311    0      0.007466   99.25    19.5063    20:26:17\n",
      "312    0      0.009097   99.09    19.1965    20:26:17\n",
      "313    0      0.009558   99.04    19.1714    20:26:17\n",
      "314    0      0.008735   99.13    19.4207    20:26:17\n",
      "315    0      0.007034   99.30    19.9175    20:26:17\n",
      "316    0      0.005218   99.48    20.6199    20:26:17\n",
      "317    0      0.004151   99.58    21.4676    20:26:17\n",
      "318    0      0.004465   99.55    22.3774    20:26:17\n",
      "319    0      0.006201   99.38    23.2417    20:26:17\n",
      "320    0      0.008613   99.14    23.9368    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "321    0      0.010395   98.96    24.3436    20:26:17\n",
      "322    0      0.010392   98.96    24.3774    20:26:17\n",
      "323    0      0.008417   99.16    24.0169    20:26:17\n",
      "324    0      0.005500   99.45    23.3166    20:26:17\n",
      "325    0      0.003271   99.67    22.3956    20:26:17\n",
      "326    0      0.002915   99.71    21.4056    20:26:17\n",
      "327    0      0.004512   99.55    20.4928    20:26:17\n",
      "328    0      0.007162   99.28    19.7694    20:26:17\n",
      "329    0      0.009620   99.04    19.3024    20:26:17\n",
      "330    0      0.010905   98.91    19.1189    20:26:17\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "331    0      0.010616   98.94    19.2174    20:26:17\n",
      "332    0      0.008947   99.11    19.5783    20:26:17\n",
      "333    0      0.006555   99.34    20.1687    20:26:17\n",
      "334    0      0.004354   99.56    20.9406    20:26:17\n",
      "335    0      0.003236   99.68    21.8268    20:26:17\n",
      "336    0      0.003718   99.63    22.7360    20:26:18\n",
      "337    0      0.005618   99.44    23.5542    20:26:18\n",
      "338    0      0.007977   99.20    24.1568    20:26:18\n",
      "339    0      0.009457   99.05    24.4332    20:26:18\n",
      "340    0      0.009139   99.09    24.3182    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "341    0      0.007214   99.28    23.8165    20:26:18\n",
      "342    0      0.004929   99.51    23.0079    20:26:18\n",
      "343    0      0.003758   99.62    22.0280    20:26:18\n",
      "344    0      0.004439   99.56    21.0322    20:26:18\n",
      "345    0      0.006600   99.34    20.1596    20:26:18\n",
      "346    0      0.009131   99.09    19.5090    20:26:18\n",
      "347    0      0.010860   98.91    19.1344    20:26:18\n",
      "348    0      0.011060   98.89    19.0533    20:26:18\n",
      "349    0      0.009638   99.04    19.2583    20:26:18\n",
      "350    0      0.007074   99.29    19.7261    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "351    0      0.004260   99.57    20.4189    20:26:18\n",
      "352    0      0.002253   99.77    21.2813    20:26:18\n",
      "353    0      0.001938   99.81    22.2338    20:26:18\n",
      "354    0      0.003607   99.64    23.1690    20:26:18\n",
      "355    0      0.006642   99.34    23.9569    20:26:18\n",
      "356    0      0.009606   99.04    24.4636    20:26:18\n",
      "357    0      0.010934   98.91    24.5836    20:26:18\n",
      "358    0      0.009945   99.01    24.2742    20:26:18\n",
      "359    0      0.007387   99.26    23.5767    20:26:18\n",
      "360    0      0.004960   99.50    22.6092    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "361    0      0.004143   99.59    21.5347    20:26:18\n",
      "362    0      0.005289   99.47    20.5184    20:26:18\n",
      "363    0      0.007603   99.24    19.6916    20:26:18\n",
      "364    0      0.009794   99.02    19.1366    20:26:18\n",
      "365    0      0.010792   98.92    18.8897    20:26:18\n",
      "366    0      0.010133   98.99    18.9544    20:26:18\n",
      "367    0      0.008022   99.20    19.3137    20:26:18\n",
      "368    0      0.005206   99.48    19.9362    20:26:18\n",
      "369    0      0.002766   99.72    20.7744    20:26:18\n",
      "370    0      0.001801   99.82    21.7581    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "371    0      0.002989   99.70    22.7871    20:26:18\n",
      "372    0      0.006108   99.39    23.7299    20:26:18\n",
      "373    0      0.009840   99.02    24.4366    20:26:18\n",
      "374    0      0.012252   98.77    24.7686    20:26:18\n",
      "375    0      0.011939   98.81    24.6412    20:26:18\n",
      "376    0      0.009090   99.09    24.0571    20:26:18\n",
      "377    0      0.005477   99.45    23.1148    20:26:18\n",
      "378    0      0.003245   99.68    21.9821    20:26:18\n",
      "379    0      0.003493   99.65    20.8483    20:26:18\n",
      "380    0      0.005774   99.42    19.8760    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "381    0      0.008671   99.13    19.1739    20:26:18\n",
      "382    0      0.010732   98.93    18.7940    20:26:18\n",
      "383    0      0.011099   98.89    18.7462    20:26:18\n",
      "384    0      0.009688   99.03    19.0150    20:26:18\n",
      "385    0      0.007079   99.29    19.5700    20:26:18\n",
      "386    0      0.004306   99.57    20.3669    20:26:18\n",
      "387    0      0.002566   99.74    21.3424    20:26:18\n",
      "388    0      0.002799   99.72    22.4052    20:26:18\n",
      "389    0      0.005179   99.48    23.4312    20:26:18\n",
      "390    0      0.008750   99.12    24.2703    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "391    0      0.011650   98.84    24.7716    20:26:18\n",
      "392    0      0.012106   98.79    24.8233    20:26:18\n",
      "393    0      0.009717   99.03    24.3942    20:26:18\n",
      "394    0      0.005896   99.41    23.5526    20:26:18\n",
      "395    0      0.002949   99.71    22.4505    20:26:18\n",
      "396    0      0.002502   99.75    21.2794    20:26:18\n",
      "397    0      0.004572   99.54    20.2184    20:26:18\n",
      "398    0      0.007865   99.21    19.3977    20:26:18\n",
      "399    0      0.010729   98.93    18.8877    20:26:18\n",
      "400    0      0.011982   98.80    18.7102    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "401    0      0.011230   98.88    18.8565    20:26:18\n",
      "402    0      0.008830   99.12    19.3007    20:26:18\n",
      "403    0      0.005697   99.43    20.0046    20:26:18\n",
      "404    0      0.003042   99.70    20.9141    20:26:18\n",
      "405    0      0.002015   99.80    21.9514    20:26:18\n",
      "406    0      0.003230   99.68    23.0074    20:26:18\n",
      "407    0      0.006293   99.37    23.9430    20:26:18\n",
      "408    0      0.009720   99.03    24.6055    20:26:18\n",
      "409    0      0.011583   98.84    24.8631    20:26:18\n",
      "410    0      0.010742   98.93    24.6468    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "411    0      0.007752   99.22    23.9808    20:26:18\n",
      "412    0      0.004562   99.54    22.9820    20:26:18\n",
      "413    0      0.003143   99.69    21.8273    20:26:18\n",
      "414    0      0.004208   99.58    20.7036    20:26:18\n",
      "415    0      0.006984   99.30    19.7627    20:26:18\n",
      "416    0      0.009947   99.01    19.1007    20:26:18\n",
      "417    0      0.011724   98.83    18.7598    20:26:18\n",
      "418    0      0.011616   98.84    18.7450    20:26:18\n",
      "419    0      0.009681   99.03    19.0392    20:26:18\n",
      "420    0      0.006607   99.34    19.6123    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "421    0      0.003497   99.65    20.4208    20:26:18\n",
      "422    0      0.001582   99.84    21.4020    20:26:18\n",
      "423    0      0.001812   99.82    22.4644    20:26:18\n",
      "424    0      0.004339   99.57    23.4838    20:26:18\n",
      "425    0      0.008168   99.18    24.3107    20:26:18\n",
      "426    0      0.011390   98.86    24.7955    20:26:18\n",
      "427    0      0.012197   98.78    24.8292    20:26:18\n",
      "428    0      0.010140   98.99    24.3839    20:26:18\n",
      "429    0      0.006568   99.34    23.5308    20:26:18\n",
      "430    0      0.003708   99.63    22.4232    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "431    0      0.003131   99.69    21.2524    20:26:18\n",
      "432    0      0.004874   99.51    20.1957    20:26:18\n",
      "433    0      0.007727   99.23    19.3812    20:26:18\n",
      "434    0      0.010157   98.98    18.8779    20:26:18\n",
      "435    0      0.011078   98.89    18.7070    20:26:18\n",
      "436    0      0.010159   98.98    18.8594    20:26:18\n",
      "437    0      0.007775   99.22    19.3091    20:26:18\n",
      "438    0      0.004832   99.52    20.0175    20:26:18\n",
      "439    0      0.002504   99.75    20.9299    20:26:18\n",
      "440    0      0.001882   99.81    21.9673    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "441    0      0.003491   99.65    23.0196    20:26:18\n",
      "442    0      0.006836   99.32    23.9468    20:26:18\n",
      "443    0      0.010341   98.97    24.5968    20:26:18\n",
      "444    0      0.012050   98.79    24.8395    20:26:18\n",
      "445    0      0.010870   98.91    24.6095    20:26:18\n",
      "446    0      0.007466   99.25    23.9351    20:26:18\n",
      "447    0      0.003892   99.61    22.9370    20:26:18\n",
      "448    0      0.002184   99.78    21.7937    20:26:18\n",
      "449    0      0.003073   99.69    20.6909    20:26:18\n",
      "450    0      0.005788   99.42    19.7777    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "451    0      0.008800   99.12    19.1461    20:26:18\n",
      "452    0      0.010731   98.93    18.8348    20:26:18\n",
      "453    0      0.010867   98.91    18.8450    20:26:18\n",
      "454    0      0.009249   99.08    19.1567    20:26:18\n",
      "455    0      0.006531   99.35    19.7364    20:26:18\n",
      "456    0      0.003752   99.62    20.5375    20:26:18\n",
      "457    0      0.002047   99.80    21.4937    20:26:18\n",
      "458    0      0.002233   99.78    22.5125    20:26:18\n",
      "459    0      0.004367   99.56    23.4723    20:26:18\n",
      "460    0      0.007495   99.25    24.2324    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "461    0      0.009952   99.00    24.6579    20:26:18\n",
      "462    0      0.010299   98.97    24.6572    20:26:18\n",
      "463    0      0.008336   99.17    24.2150    20:26:18\n",
      "464    0      0.005336   99.47    23.4051    20:26:18\n",
      "465    0      0.003174   99.68    22.3715    20:26:18\n",
      "466    0      0.003059   99.69    21.2878    20:26:18\n",
      "467    0      0.004882   99.51    20.3128    20:26:18\n",
      "468    0      0.007527   99.25    19.5610    20:26:18\n",
      "469    0      0.009654   99.03    19.0952    20:26:18\n",
      "470    0      0.010341   98.97    18.9361    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "471    0      0.009329   99.07    19.0769    20:26:18\n",
      "472    0      0.006990   99.30    19.4946    20:26:18\n",
      "473    0      0.004162   99.58    20.1530    20:26:18\n",
      "474    0      0.001913   99.81    21.0000    20:26:18\n",
      "475    0      0.001224   99.88    21.9608    20:26:18\n",
      "476    0      0.002565   99.74    22.9329    20:26:18\n",
      "477    0      0.005515   99.45    23.7877    20:26:18\n",
      "478    0      0.008727   99.13    24.3873    20:26:18\n",
      "479    0      0.010510   98.95    24.6146    20:26:18\n",
      "480    0      0.009867   99.01    24.4106    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "481    0      0.007246   99.28    23.7997    20:26:18\n",
      "482    0      0.004280   99.57    22.8885    20:26:18\n",
      "483    0      0.002670   99.73    21.8373    20:26:18\n",
      "484    0      0.003112   99.69    20.8151    20:26:18\n",
      "485    0      0.005073   99.49    19.9611    20:26:18\n",
      "486    0      0.007347   99.27    19.3648    20:26:18\n",
      "487    0      0.008799   99.12    19.0670    20:26:18\n",
      "488    0      0.008823   99.12    19.0729    20:26:18\n",
      "489    0      0.007449   99.26    19.3651    20:26:18\n",
      "490    0      0.005245   99.48    19.9116    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "491    0      0.003106   99.69    20.6655    20:26:18\n",
      "492    0      0.001980   99.80    21.5609    20:26:18\n",
      "493    0      0.002498   99.75    22.5070    20:26:18\n",
      "494    0      0.004591   99.54    23.3877    20:26:18\n",
      "495    0      0.007324   99.27    24.0723    20:26:18\n",
      "496    0      0.009225   99.08    24.4389    20:26:18\n",
      "497    0      0.009130   99.09    24.4090    20:26:18\n",
      "498    0      0.007022   99.30    23.9756    20:26:18\n",
      "499    0      0.004143   99.59    23.2126    20:26:18\n",
      "500    0      0.002170   99.78    22.2561    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "501    0      0.002123   99.79    21.2663    20:26:18\n",
      "502    0      0.003845   99.62    20.3878    20:26:18\n",
      "503    0      0.006304   99.37    19.7236    20:26:18\n",
      "504    0      0.008290   99.17    19.3295    20:26:18\n",
      "505    0      0.008980   99.10    19.2222    20:26:18\n",
      "506    0      0.008161   99.18    19.3929    20:26:18\n",
      "507    0      0.006188   99.38    19.8160    20:26:18\n",
      "508    0      0.003822   99.62    20.4523    20:26:18\n",
      "509    0      0.001989   99.80    21.2461    20:26:18\n",
      "510    0      0.001469   99.85    22.1212    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "511    0      0.002546   99.75    22.9784    20:26:18\n",
      "512    0      0.004767   99.52    23.7009    20:26:18\n",
      "513    0      0.007024   99.30    24.1720    20:26:18\n",
      "514    0      0.008108   99.19    24.3014    20:26:18\n",
      "515    0      0.007461   99.25    24.0539    20:26:18\n",
      "516    0      0.005591   99.44    23.4653    20:26:18\n",
      "517    0      0.003731   99.63    22.6368    20:26:18\n",
      "518    0      0.002992   99.70    21.7078    20:26:18\n",
      "519    0      0.003687   99.63    20.8206    20:26:18\n",
      "520    0      0.005278   99.47    20.0909    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "521    0      0.006832   99.32    19.5940    20:26:18\n",
      "522    0      0.007545   99.25    19.3656    20:26:18\n",
      "523    0      0.007064   99.29    19.4117    20:26:18\n",
      "524    0      0.005546   99.45    19.7174    20:26:18\n",
      "525    0      0.003566   99.64    20.2518    20:26:18\n",
      "526    0      0.001931   99.81    20.9678    20:26:18\n",
      "527    0      0.001410   99.86    21.7977    20:26:18\n",
      "528    0      0.002398   99.76    22.6504    20:26:18\n",
      "529    0      0.004614   99.54    23.4138    20:26:18\n",
      "530    0      0.007063   99.29    23.9675    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "531    0      0.008452   99.15    24.2085    20:26:18\n",
      "532    0      0.007965   99.20    24.0808    20:26:18\n",
      "533    0      0.005861   99.41    23.5980    20:26:18\n",
      "534    0      0.003361   99.66    22.8445    20:26:18\n",
      "535    0      0.001841   99.82    21.9536    20:26:18\n",
      "536    0      0.001979   99.80    21.0712    20:26:18\n",
      "537    0      0.003475   99.65    20.3222    20:26:18\n",
      "538    0      0.005410   99.46    19.7910    20:26:18\n",
      "539    0      0.006828   99.32    19.5195    20:26:18\n",
      "540    0      0.007156   99.28    19.5162    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "541    0      0.006338   99.37    19.7667    20:26:18\n",
      "542    0      0.004775   99.52    20.2401    20:26:18\n",
      "543    0      0.003146   99.69    20.8906    20:26:18\n",
      "544    0      0.002167   99.78    21.6550    20:26:18\n",
      "545    0      0.002299   99.77    22.4503    20:26:18\n",
      "546    0      0.003485   99.65    23.1760    20:26:18\n",
      "547    0      0.005087   99.49    23.7241    20:26:18\n",
      "548    0      0.006166   99.38    24.0000    20:26:18\n",
      "549    0      0.006048   99.40    23.9475    20:26:18\n",
      "550    0      0.004814   99.52    23.5687    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "551    0      0.003283   99.67    22.9279    20:26:18\n",
      "552    0      0.002453   99.75    22.1358    20:26:18\n",
      "553    0      0.002837   99.72    21.3207    20:26:18\n",
      "554    0      0.004197   99.58    20.5989    20:26:18\n",
      "555    0      0.005785   99.42    20.0563    20:26:18\n",
      "556    0      0.006799   99.32    19.7422    20:26:18\n",
      "557    0      0.006758   99.32    19.6751    20:26:18\n",
      "558    0      0.005643   99.44    19.8502    20:26:18\n",
      "559    0      0.003853   99.61    20.2455    20:26:18\n",
      "560    0      0.002067   99.79    20.8231    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "561    0      0.001018   99.90    21.5280    20:26:18\n",
      "562    0      0.001224   99.88    22.2849    20:26:18\n",
      "563    0      0.002711   99.73    22.9999    20:26:18\n",
      "564    0      0.004888   99.51    23.5676    20:26:18\n",
      "565    0      0.006730   99.33    23.8898    20:26:18\n",
      "566    0      0.007308   99.27    23.8993    20:26:18\n",
      "567    0      0.006371   99.36    23.5829    20:26:18\n",
      "568    0      0.004540   99.55    22.9903    20:26:18\n",
      "569    0      0.002890   99.71    22.2241    20:26:18\n",
      "570    0      0.002257   99.77    21.4128    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "571    0      0.002779   99.72    20.6801    20:26:18\n",
      "572    0      0.003957   99.60    20.1211    20:26:18\n",
      "573    0      0.005057   99.49    19.7932    20:26:18\n",
      "574    0      0.005512   99.45    19.7189    20:26:18\n",
      "575    0      0.005140   99.49    19.8936    20:26:18\n",
      "576    0      0.004167   99.58    20.2924    20:26:18\n",
      "577    0      0.003097   99.69    20.8730    20:26:18\n",
      "578    0      0.002508   99.75    21.5745    20:26:18\n",
      "579    0      0.002774   99.72    22.3167    20:26:18\n",
      "580    0      0.003835   99.62    23.0022    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "581    0      0.005126   99.49    23.5270    20:26:18\n",
      "582    0      0.005833   99.42    23.7998    20:26:18\n",
      "583    0      0.005407   99.46    23.7664    20:26:18\n",
      "584    0      0.003993   99.60    23.4281    20:26:18\n",
      "585    0      0.002405   99.76    22.8453    20:26:18\n",
      "586    0      0.001592   99.84    22.1220    20:26:18\n",
      "587    0      0.002028   99.80    21.3785    20:26:18\n",
      "588    0      0.003466   99.65    20.7229    20:26:18\n",
      "589    0      0.005171   99.48    20.2341    20:26:18\n",
      "590    0      0.006356   99.36    19.9571    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "591    0      0.006534   99.35    19.9075    20:26:18\n",
      "592    0      0.005653   99.43    20.0793    20:26:18\n",
      "593    0      0.004061   99.59    20.4499    20:26:18\n",
      "594    0      0.002361   99.76    20.9819    20:26:18\n",
      "595    0      0.001213   99.88    21.6219    20:26:18\n",
      "596    0      0.001085   99.89    22.2989    20:26:18\n",
      "597    0      0.002035   99.80    22.9266    20:26:18\n",
      "598    0      0.003619   99.64    23.4115    20:26:18\n",
      "599    0      0.005063   99.49    23.6691    20:26:18\n",
      "600    0      0.005674   99.43    23.6455    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "601    0      0.005266   99.47    23.3349    20:26:18\n",
      "602    0      0.004264   99.57    22.7862    20:26:18\n",
      "603    0      0.003382   99.66    22.0925    20:26:18\n",
      "604    0      0.003129   99.69    21.3680    20:26:18\n",
      "605    0      0.003524   99.65    20.7220    20:26:18\n",
      "606    0      0.004172   99.58    20.2392    20:26:18\n",
      "607    0      0.004574   99.54    19.9718    20:26:18\n",
      "608    0      0.004411   99.56    19.9407    20:26:18\n",
      "609    0      0.003692   99.63    20.1419    20:26:18\n",
      "610    0      0.002733   99.73    20.5503    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "611    0      0.002032   99.80    21.1223    20:26:18\n",
      "612    0      0.002051   99.79    21.7942    20:26:18\n",
      "613    0      0.002970   99.70    22.4830    20:26:18\n",
      "614    0      0.004496   99.55    23.0901    20:26:18\n",
      "615    0      0.005892   99.41    23.5152    20:26:18\n",
      "616    0      0.006334   99.37    23.6771    20:26:18\n",
      "617    0      0.005440   99.46    23.5376    20:26:18\n",
      "618    0      0.003609   99.64    23.1173    20:26:18\n",
      "619    0      0.001825   99.82    22.4928    20:26:18\n",
      "620    0      0.001031   99.90    21.7776    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "621    0      0.001563   99.84    21.0913    20:26:18\n",
      "622    0      0.003042   99.70    20.5335    20:26:18\n",
      "623    0      0.004688   99.53    20.1694    20:26:18\n",
      "624    0      0.005770   99.42    20.0295    20:26:18\n",
      "625    0      0.005906   99.41    20.1155    20:26:18\n",
      "626    0      0.005141   99.49    20.4082    20:26:18\n",
      "627    0      0.003867   99.61    20.8715    20:26:18\n",
      "628    0      0.002642   99.74    21.4540    20:26:18\n",
      "629    0      0.001959   99.80    22.0884    20:26:18\n",
      "630    0      0.002038   99.80    22.6938    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "631    0      0.002708   99.73    23.1828    20:26:18\n",
      "632    0      0.003504   99.65    23.4755    20:26:18\n",
      "633    0      0.003948   99.61    23.5174    20:26:18\n",
      "634    0      0.003873   99.61    23.2955    20:26:18\n",
      "635    0      0.003520   99.65    22.8449    20:26:18\n",
      "636    0      0.003333   99.67    22.2413    20:26:18\n",
      "637    0      0.003606   99.64    21.5835    20:26:18\n",
      "638    0      0.004270   99.57    20.9705    20:26:18\n",
      "639    0      0.004952   99.50    20.4844    20:26:18\n",
      "640    0      0.005217   99.48    20.1814    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "641    0      0.004806   99.52    20.0904    20:26:18\n",
      "642    0      0.003759   99.62    20.2168    20:26:18\n",
      "643    0      0.002416   99.76    20.5458    20:26:18\n",
      "644    0      0.001305   99.87    21.0436    20:26:18\n",
      "645    0      0.000961   99.90    21.6565    20:26:18\n",
      "646    0      0.001680   99.83    22.3101    20:26:18\n",
      "647    0      0.003300   99.67    22.9120    20:26:18\n",
      "648    0      0.005157   99.48    23.3627    20:26:18\n",
      "649    0      0.006342   99.37    23.5747    20:26:18\n",
      "650    0      0.006212   99.38    23.4973    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "651    0      0.004843   99.52    23.1354    20:26:18\n",
      "652    0      0.003016   99.70    22.5533    20:26:18\n",
      "653    0      0.001705   99.83    21.8584    20:26:18\n",
      "654    0      0.001473   99.85    21.1727    20:26:18\n",
      "655    0      0.002216   99.78    20.6035    20:26:18\n",
      "656    0      0.003367   99.66    20.2252    20:26:18\n",
      "657    0      0.004296   99.57    20.0750    20:26:18\n",
      "658    0      0.004623   99.54    20.1584    20:26:18\n",
      "659    0      0.004333   99.57    20.4563    20:26:18\n",
      "660    0      0.003713   99.63    20.9298    20:26:18\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "661    0      0.003186   99.68    21.5221    20:26:18\n",
      "662    0      0.003078   99.69    22.1590    20:26:18\n",
      "663    0      0.003424   99.66    22.7521    20:26:18\n",
      "664    0      0.003908   99.61    23.2087    20:26:18\n",
      "665    0      0.004046   99.60    23.4484    20:26:18\n",
      "666    0      0.003540   99.65    23.4239    20:26:19\n",
      "667    0      0.002573   99.74    23.1366    20:26:19\n",
      "668    0      0.001746   99.83    22.6396    20:26:19\n",
      "669    0      0.001673   99.83    22.0239    20:26:19\n",
      "670    0      0.002538   99.75    21.3947    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "671    0      0.003980   99.60    20.8470    20:26:19\n",
      "672    0      0.005327   99.47    20.4510    20:26:19\n",
      "673    0      0.005966   99.40    20.2470    20:26:19\n",
      "674    0      0.005608   99.44    20.2495    20:26:19\n",
      "675    0      0.004375   99.56    20.4517    20:26:19\n",
      "676    0      0.002723   99.73    20.8296    20:26:19\n",
      "677    0      0.001279   99.87    21.3423    20:26:19\n",
      "678    0      0.000623   99.94    21.9319    20:26:19\n",
      "679    0      0.001048   99.90    22.5235    20:26:19\n",
      "680    0      0.002389   99.76    23.0300    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "681    0      0.004044   99.60    23.3644    20:26:19\n",
      "682    0      0.005243   99.48    23.4582    20:26:19\n",
      "683    0      0.005489   99.45    23.2818    20:26:19\n",
      "684    0      0.004845   99.52    22.8573    20:26:19\n",
      "685    0      0.003861   99.61    22.2571    20:26:19\n",
      "686    0      0.003151   99.68    21.5863    20:26:19\n",
      "687    0      0.003002   99.70    20.9569    20:26:19\n",
      "688    0      0.003264   99.67    20.4642    20:26:19\n",
      "689    0      0.003553   99.64    20.1726    20:26:19\n",
      "690    0      0.003539   99.65    20.1133    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "691    0      0.003145   99.69    20.2878    20:26:19\n",
      "692    0      0.002583   99.74    20.6728    20:26:19\n",
      "693    0      0.002248   99.78    21.2225    20:26:19\n",
      "694    0      0.002505   99.75    21.8687    20:26:19\n",
      "695    0      0.003440   99.66    22.5222    20:26:19\n",
      "696    0      0.004695   99.53    23.0795    20:26:19\n",
      "697    0      0.005558   99.44    23.4394    20:26:19\n",
      "698    0      0.005370   99.46    23.5269    20:26:19\n",
      "699    0      0.004039   99.60    23.3178    20:26:19\n",
      "700    0      0.002211   99.78    22.8503    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "701    0      0.000893   99.91    22.2168    20:26:19\n",
      "702    0      0.000789   99.92    21.5370    20:26:19\n",
      "703    0      0.001884   99.81    20.9264    20:26:19\n",
      "704    0      0.003551   99.64    20.4720    20:26:19\n",
      "705    0      0.004985   99.50    20.2243    20:26:19\n",
      "706    0      0.005609   99.44    20.1999    20:26:19\n",
      "707    0      0.005268   99.47    20.3899    20:26:19\n",
      "708    0      0.004209   99.58    20.7655    20:26:19\n",
      "709    0      0.002934   99.71    21.2811    20:26:19\n",
      "710    0      0.001981   99.80    21.8746    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "711    0      0.001692   99.83    22.4682    20:26:19\n",
      "712    0      0.002053   99.79    22.9742    20:26:19\n",
      "713    0      0.002707   99.73    23.3075    20:26:19\n",
      "714    0      0.003187   99.68    23.4035    20:26:19\n",
      "715    0      0.003253   99.67    23.2378    20:26:19\n",
      "716    0      0.003058   99.69    22.8355    20:26:19\n",
      "717    0      0.002995   99.70    22.2682    20:26:19\n",
      "718    0      0.003345   99.67    21.6353    20:26:19\n",
      "719    0      0.004035   99.60    21.0406    20:26:19\n",
      "720    0      0.004687   99.53    20.5711    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "721    0      0.004865   99.51    20.2865    20:26:19\n",
      "722    0      0.004336   99.57    20.2173    20:26:19\n",
      "723    0      0.003196   99.68    20.3679    20:26:19\n",
      "724    0      0.001845   99.82    20.7205    20:26:19\n",
      "725    0      0.000858   99.91    21.2357    20:26:19\n",
      "726    0      0.000758   99.92    21.8526    20:26:19\n",
      "727    0      0.001752   99.82    22.4880    20:26:19\n",
      "728    0      0.003531   99.65    23.0419    20:26:19\n",
      "729    0      0.005295   99.47    23.4117    20:26:19\n",
      "730    0      0.006133   99.39    23.5158    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "731    0      0.005593   99.44    23.3194    20:26:19\n",
      "732    0      0.004030   99.60    22.8511    20:26:19\n",
      "733    0      0.002384   99.76    22.1995    20:26:19\n",
      "734    0      0.001528   99.85    21.4887    20:26:19\n",
      "735    0      0.001739   99.83    20.8450    20:26:19\n",
      "736    0      0.002651   99.73    20.3685    20:26:19\n",
      "737    0      0.003612   99.64    20.1199    20:26:19\n",
      "738    0      0.004107   99.59    20.1213    20:26:19\n",
      "739    0      0.003983   99.60    20.3630    20:26:19\n",
      "740    0      0.003464   99.65    20.8106    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "741    0      0.002984   99.70    21.4073    20:26:19\n",
      "742    0      0.002931   99.71    22.0745    20:26:19\n",
      "743    0      0.003389   99.66    22.7146    20:26:19\n",
      "744    0      0.004018   99.60    23.2210    20:26:19\n",
      "745    0      0.004228   99.58    23.4979    20:26:19\n",
      "746    0      0.003625   99.64    23.4857    20:26:19\n",
      "747    0      0.002401   99.76    23.1825    20:26:19\n",
      "748    0      0.001293   99.87    22.6479    20:26:19\n",
      "749    0      0.001063   99.89    21.9868    20:26:19\n",
      "750    0      0.001951   99.80    21.3198    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "751    0      0.003531   99.65    20.7533    20:26:19\n",
      "752    0      0.005026   99.50    20.3622    20:26:19\n",
      "753    0      0.005751   99.42    20.1864    20:26:19\n",
      "754    0      0.005408   99.46    20.2363    20:26:19\n",
      "755    0      0.004158   99.58    20.4989    20:26:19\n",
      "756    0      0.002519   99.75    20.9421    20:26:19\n",
      "757    0      0.001162   99.88    21.5151    20:26:19\n",
      "758    0      0.000654   99.93    22.1474    20:26:19\n",
      "759    0      0.001192   99.88    22.7500    20:26:19\n",
      "760    0      0.002459   99.75    23.2238    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "761    0      0.003755   99.62    23.4772    20:26:19\n",
      "762    0      0.004402   99.56    23.4501    20:26:19\n",
      "763    0      0.004199   99.58    23.1356    20:26:19\n",
      "764    0      0.003528   99.65    22.5877    20:26:19\n",
      "765    0      0.003017   99.70    21.9086    20:26:19\n",
      "766    0      0.003034   99.70    21.2217    20:26:19\n",
      "767    0      0.003461   99.65    20.6409    20:26:19\n",
      "768    0      0.003858   99.61    20.2502    20:26:19\n",
      "769    0      0.003808   99.62    20.0966    20:26:19\n",
      "770    0      0.003180   99.68    20.1931    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "771    0      0.002211   99.78    20.5243    20:26:19\n",
      "772    0      0.001405   99.86    21.0503    20:26:19\n",
      "773    0      0.001305   99.87    21.7067    20:26:19\n",
      "774    0      0.002193   99.78    22.4035    20:26:19\n",
      "775    0      0.003818   99.62    23.0300    20:26:19\n",
      "776    0      0.005381   99.46    23.4689    20:26:19\n",
      "777    0      0.005920   99.41    23.6234    20:26:19\n",
      "778    0      0.004989   99.50    23.4477    20:26:19\n",
      "779    0      0.003073   99.69    22.9689    20:26:19\n",
      "780    0      0.001315   99.87    22.2832    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "781    0      0.000709   99.93    21.5281    20:26:19\n",
      "782    0      0.001454   99.85    20.8427    20:26:19\n",
      "783    0      0.002967   99.70    20.3352    20:26:19\n",
      "784    0      0.004365   99.56    20.0689    20:26:19\n",
      "785    0      0.004993   99.50    20.0648    20:26:19\n",
      "786    0      0.004683   99.53    20.3112    20:26:19\n",
      "787    0      0.003735   99.63    20.7719    20:26:19\n",
      "788    0      0.002723   99.73    21.3886    20:26:19\n",
      "789    0      0.002201   99.78    22.0810    20:26:19\n",
      "790    0      0.002395   99.76    22.7485    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "791    0      0.003040   99.70    23.2798    20:26:19\n",
      "792    0      0.003529   99.65    23.5729    20:26:19\n",
      "793    0      0.003363   99.66    23.5629    20:26:19\n",
      "794    0      0.002600   99.74    23.2446    20:26:19\n",
      "795    0      0.001858   99.81    22.6788    20:26:19\n",
      "796    0      0.001826   99.82    21.9761    20:26:19\n",
      "797    0      0.002707   99.73    21.2652    20:26:19\n",
      "798    0      0.004081   99.59    20.6612    20:26:19\n",
      "799    0      0.005210   99.48    20.2468    20:26:19\n",
      "800    0      0.005487   99.45    20.0669    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "801    0      0.004718   99.53    20.1343    20:26:19\n",
      "802    0      0.003179   99.68    20.4362    20:26:19\n",
      "803    0      0.001502   99.85    20.9379    20:26:19\n",
      "804    0      0.000434   99.96    21.5821    20:26:19\n",
      "805    0      0.000527   99.95    22.2864    20:26:19\n",
      "806    0      0.001816   99.82    22.9453    20:26:19\n",
      "807    0      0.003677   99.63    23.4411    20:26:19\n",
      "808    0      0.005089   99.49    23.6679    20:26:19\n",
      "809    0      0.005266   99.47    23.5631    20:26:19\n",
      "810    0      0.004238   99.58    23.1344    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "811    0      0.002832   99.72    22.4636    20:26:19\n",
      "812    0      0.002012   99.80    21.6842    20:26:19\n",
      "813    0      0.002175   99.78    20.9428    20:26:19\n",
      "814    0      0.002988   99.70    20.3623    20:26:19\n",
      "815    0      0.003759   99.62    20.0220    20:26:19\n",
      "816    0      0.003937   99.61    19.9563    20:26:19\n",
      "817    0      0.003401   99.66    20.1633    20:26:19\n",
      "818    0      0.002481   99.75    20.6128    20:26:19\n",
      "819    0      0.001782   99.82    21.2492    20:26:19\n",
      "820    0      0.001869   99.81    21.9907    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "821    0      0.002905   99.71    22.7288    20:26:19\n",
      "822    0      0.004413   99.56    23.3367    20:26:19\n",
      "823    0      0.005427   99.46    23.6913    20:26:19\n",
      "824    0      0.005111   99.49    23.7069    20:26:19\n",
      "825    0      0.003479   99.65    23.3679    20:26:19\n",
      "826    0      0.001519   99.85    22.7411    20:26:19\n",
      "827    0      0.000494   99.95    21.9580    20:26:19\n",
      "828    0      0.001013   99.90    21.1738    20:26:19\n",
      "829    0      0.002685   99.73    20.5245    20:26:19\n",
      "830    0      0.004519   99.55    20.1012    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "831    0      0.005584   99.44    19.9465    20:26:19\n",
      "832    0      0.005452   99.45    20.0641    20:26:19\n",
      "833    0      0.004295   99.57    20.4297    20:26:19\n",
      "834    0      0.002732   99.73    20.9964    20:26:19\n",
      "835    0      0.001539   99.85    21.6950    20:26:19\n",
      "836    0      0.001290   99.87    22.4322    20:26:19\n",
      "837    0      0.002032   99.80    23.0942    20:26:19\n",
      "838    0      0.003206   99.68    23.5614    20:26:19\n",
      "839    0      0.003973   99.60    23.7344    20:26:19\n",
      "840    0      0.003832   99.62    23.5658    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "841    0      0.003033   99.70    23.0806    20:26:19\n",
      "842    0      0.002367   99.76    22.3738    20:26:19\n",
      "843    0      0.002490   99.75    21.5828    20:26:19\n",
      "844    0      0.003411   99.66    20.8491    20:26:19\n",
      "845    0      0.004541   99.55    20.2862    20:26:19\n",
      "846    0      0.005145   99.49    19.9656    20:26:19\n",
      "847    0      0.004788   99.52    19.9178    20:26:19\n",
      "848    0      0.003532   99.65    20.1406    20:26:19\n",
      "849    0      0.001900   99.81    20.6060    20:26:19\n",
      "850    0      0.000674   99.93    21.2610    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "851    0      0.000564   99.94    22.0252    20:26:19\n",
      "852    0      0.001805   99.82    22.7887    20:26:19\n",
      "853    0      0.003874   99.61    23.4199    20:26:19\n",
      "854    0      0.005614   99.44    23.7878    20:26:19\n",
      "855    0      0.005924   99.41    23.7992    20:26:19\n",
      "856    0      0.004600   99.54    23.4349    20:26:19\n",
      "857    0      0.002576   99.74    22.7650    20:26:19\n",
      "858    0      0.001204   99.88    21.9303    20:26:19\n",
      "859    0      0.001239   99.88    21.0978    20:26:19\n",
      "860    0      0.002414   99.76    20.4135    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "861    0      0.003831   99.62    19.9750    20:26:19\n",
      "862    0      0.004632   99.54    19.8268    20:26:19\n",
      "863    0      0.004447   99.56    19.9718    20:26:19\n",
      "864    0      0.003486   99.65    20.3823    20:26:19\n",
      "865    0      0.002372   99.76    21.0061    20:26:19\n",
      "866    0      0.001828   99.82    21.7652    20:26:19\n",
      "867    0      0.002275   99.77    22.5543    20:26:19\n",
      "868    0      0.003502   99.65    23.2448    20:26:19\n",
      "869    0      0.004658   99.53    23.7038    20:26:19\n",
      "870    0      0.004778   99.52    23.8269    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "871    0      0.003579   99.64    23.5749    20:26:19\n",
      "872    0      0.001822   99.82    22.9953    20:26:19\n",
      "873    0      0.000771   99.92    22.2108    20:26:19\n",
      "874    0      0.001202   99.88    21.3811    20:26:19\n",
      "875    0      0.002862   99.71    20.6554    20:26:19\n",
      "876    0      0.004766   99.52    20.1411    20:26:19\n",
      "877    0      0.005893   99.41    19.8948    20:26:19\n",
      "878    0      0.005717   99.43    19.9309    20:26:19\n",
      "879    0      0.004362   99.56    20.2334    20:26:19\n",
      "880    0      0.002475   99.75    20.7631    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "881    0      0.000947   99.91    21.4580    20:26:19\n",
      "882    0      0.000536   99.95    22.2303    20:26:19\n",
      "883    0      0.001468   99.85    22.9666    20:26:19\n",
      "884    0      0.003217   99.68    23.5377    20:26:19\n",
      "885    0      0.004722   99.53    23.8241    20:26:19\n",
      "886    0      0.005066   99.49    23.7509    20:26:19\n",
      "887    0      0.004180   99.58    23.3187    20:26:19\n",
      "888    0      0.002896   99.71    22.6105    20:26:19\n",
      "889    0      0.002241   99.78    21.7692    20:26:19\n",
      "890    0      0.002633   99.74    20.9544    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "891    0      0.003673   99.63    20.3020    20:26:19\n",
      "892    0      0.004558   99.54    19.9007    20:26:19\n",
      "893    0      0.004655   99.53    19.7914    20:26:19\n",
      "894    0      0.003823   99.62    19.9759    20:26:19\n",
      "895    0      0.002455   99.75    20.4270    20:26:19\n",
      "896    0      0.001292   99.87    21.0914    20:26:19\n",
      "897    0      0.001084   99.89    21.8874    20:26:19\n",
      "898    0      0.002160   99.78    22.7021    20:26:19\n",
      "899    0      0.004080   99.59    23.3976    20:26:19\n",
      "900    0      0.005698   99.43    23.8326    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "901    0      0.005849   99.42    23.9014    20:26:19\n",
      "902    0      0.004289   99.57    23.5739    20:26:19\n",
      "903    0      0.002022   99.80    22.9152    20:26:19\n",
      "904    0      0.000556   99.94    22.0679    20:26:19\n",
      "905    0      0.000750   99.92    21.2056    20:26:19\n",
      "906    0      0.002306   99.77    20.4818    20:26:19\n",
      "907    0      0.004178   99.58    19.9995    20:26:19\n",
      "908    0      0.005337   99.47    19.8068    20:26:19\n",
      "909    0      0.005287   99.47    19.9085    20:26:19\n",
      "910    0      0.004181   99.58    20.2793    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "911    0      0.002657   99.73    20.8712    20:26:19\n",
      "912    0      0.001535   99.85    21.6119    20:26:19\n",
      "913    0      0.001424   99.86    22.4032    20:26:19\n",
      "914    0      0.002349   99.77    23.1226    20:26:19\n",
      "915    0      0.003638   99.64    23.6380    20:26:19\n",
      "916    0      0.004309   99.57    23.8377    20:26:19\n",
      "917    0      0.003816   99.62    23.6673    20:26:19\n",
      "918    0      0.002561   99.74    23.1540    20:26:19\n",
      "919    0      0.001600   99.84    22.4046    20:26:19\n",
      "920    0      0.001756   99.82    21.5716    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "921    0      0.002992   99.70    20.8084    20:26:19\n",
      "922    0      0.004524   99.55    20.2333    20:26:19\n",
      "923    0      0.005431   99.46    19.9161    20:26:19\n",
      "924    0      0.005187   99.48    19.8828    20:26:19\n",
      "925    0      0.003865   99.61    20.1260    20:26:19\n",
      "926    0      0.002059   99.79    20.6132    20:26:19\n",
      "927    0      0.000639   99.94    21.2881    20:26:19\n",
      "928    0      0.000383   99.96    22.0670    20:26:19\n",
      "929    0      0.001562   99.84    22.8377    20:26:19\n",
      "930    0      0.003652   99.63    23.4671    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "931    0      0.005470   99.45    23.8244    20:26:19\n",
      "932    0      0.005885   99.41    23.8187    20:26:19\n",
      "933    0      0.004677   99.53    23.4343    20:26:19\n",
      "934    0      0.002756   99.72    22.7456    20:26:19\n",
      "935    0      0.001454   99.85    21.8962    20:26:19\n",
      "936    0      0.001501   99.85    21.0550    20:26:19\n",
      "937    0      0.002628   99.74    20.3684    20:26:19\n",
      "938    0      0.003952   99.60    19.9335    20:26:19\n",
      "939    0      0.004641   99.54    19.7947    20:26:19\n",
      "940    0      0.004352   99.56    19.9537    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "941    0      0.003319   99.67    20.3819    20:26:19\n",
      "942    0      0.002187   99.78    21.0250    20:26:19\n",
      "943    0      0.001688   99.83    21.8022    20:26:19\n",
      "944    0      0.002223   99.78    22.6039    20:26:19\n",
      "945    0      0.003527   99.65    23.2976    20:26:19\n",
      "946    0      0.004690   99.53    23.7479    20:26:19\n",
      "947    0      0.004743   99.53    23.8521    20:26:19\n",
      "948    0      0.003464   99.65    23.5775    20:26:19\n",
      "949    0      0.001687   99.83    22.9793    20:26:19\n",
      "950    0      0.000680   99.93    22.1863    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "951    0      0.001148   99.89    21.3590    20:26:19\n",
      "952    0      0.002776   99.72    20.6435    20:26:19\n",
      "953    0      0.004580   99.54    20.1420    20:26:19\n",
      "954    0      0.005596   99.44    19.9073    20:26:19\n",
      "955    0      0.005357   99.46    19.9514    20:26:19\n",
      "956    0      0.004014   99.60    20.2570    20:26:19\n",
      "957    0      0.002208   99.78    20.7847    20:26:19\n",
      "958    0      0.000790   99.92    21.4722    20:26:19\n",
      "959    0      0.000464   99.95    22.2318    20:26:19\n",
      "960    0      0.001406   99.86    22.9505    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "961    0      0.003066   99.69    23.5015    20:26:19\n",
      "962    0      0.004411   99.56    23.7689    20:26:19\n",
      "963    0      0.004608   99.54    23.6832    20:26:19\n",
      "964    0      0.003668   99.63    23.2506    20:26:19\n",
      "965    0      0.002435   99.76    22.5573    20:26:19\n",
      "966    0      0.001871   99.81    21.7454    20:26:19\n",
      "967    0      0.002309   99.77    20.9697    20:26:19\n",
      "968    0      0.003314   99.67    20.3585    20:26:19\n",
      "969    0      0.004119   99.59    19.9941    20:26:19\n",
      "970    0      0.004161   99.58    19.9120    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "971    0      0.003361   99.66    20.1107    20:26:19\n",
      "972    0      0.002129   99.79    20.5601    20:26:19\n",
      "973    0      0.001162   99.88    21.2050    20:26:19\n",
      "974    0      0.001118   99.89    21.9625    20:26:19\n",
      "975    0      0.002215   99.78    22.7219    20:26:19\n",
      "976    0      0.003965   99.60    23.3520    20:26:19\n",
      "977    0      0.005301   99.47    23.7238    20:26:19\n",
      "978    0      0.005248   99.48    23.7470    20:26:19\n",
      "979    0      0.003717   99.63    23.4041    20:26:19\n",
      "980    0      0.001690   99.83    22.7647    20:26:19\n",
      "\n",
      "Recent Training Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch  Batch  Loss       Acc(%)   LTC Norm   Time    \n",
      "--------------------------------------------------------------------------------\n",
      "981    0      0.000494   99.95    21.9659    20:26:19\n",
      "982    0      0.000816   99.92    21.1689    20:26:19\n",
      "983    0      0.002315   99.77    20.5137    20:26:19\n",
      "984    0      0.004022   99.60    20.0927    20:26:19\n",
      "985    0      0.005022   99.50    19.9476    20:26:19\n",
      "986    0      0.004896   99.51    20.0797    20:26:19\n",
      "987    0      0.003820   99.62    20.4617    20:26:19\n",
      "988    0      0.002406   99.76    21.0428    20:26:19\n",
      "989    0      0.001398   99.86    21.7492    20:26:19\n",
      "990    0      0.001307   99.87    22.4833    20:26:19\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Example Usage\n",
    "# Initialize components\n",
    "metronome = MetronomeTime(tick_rate=0.01)\n",
    "harmonic_embed = HarmonicEmbedding(embedding_dim=32, num_harmonics=8)\n",
    "ltc_neuron = PersistentLTCNeuron(input_size=8, hidden_size=32)\n",
    "\n",
    "# Register LTC neuron with metronome\n",
    "ltc_neuron.lobe_id = 'lobe_1'\n",
    "metronome.register_lobe('lobe_1')\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "# Train and visualize\n",
    "losses, times = train_ltc_with_harmonics(\n",
    "    ltc_neuron, \n",
    "    harmonic_embed,\n",
    "    metronome,\n",
    "    num_epochs=1000\n",
    ")\n",
    "\n",
    "# Save trained components\n",
    "save_dir = Path('trained_components')\n",
    "save_dir.mkdir(exist_ok=True)\n",
    "\n",
    "metronome.save_state(save_dir / 'metronome.pkl')\n",
    "harmonic_embed.save_embeddings(save_dir / 'harmonics.pt')\n",
    "ltc_neuron.save_state(save_dir / 'ltc.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
