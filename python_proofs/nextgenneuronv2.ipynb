{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple\n",
    "from dataclasses import dataclass\n",
    "from IPython.display import clear_output, display\n",
    "import time\n",
    "\n",
    "@dataclass\n",
    "class AttentionState:\n",
    "    temporal_weight: float = 0.0\n",
    "    causal_weight: float = 0.0\n",
    "    novelty_weight: float = 0.0\n",
    "    \n",
    "    def compute_total(self) -> float:\n",
    "        return (self.temporal_weight + self.causal_weight + self.novelty_weight) / 3.0\n",
    "\n",
    "class CausalAttention:\n",
    "    def __init__(self, decay_rate=0.1, novelty_threshold=0.3, memory_length=100):\n",
    "        self.states: Dict[int, AttentionState] = {}\n",
    "        self.history: List[Tuple[int, float]] = []\n",
    "        self.decay_rate = decay_rate\n",
    "        self.novelty_threshold = novelty_threshold\n",
    "        self.memory_length = memory_length\n",
    "    \n",
    "    def update(self, neuron_id: int, prediction_error: float, current_state: float, target_state: float) -> float:\n",
    "        state = self.states.get(neuron_id, AttentionState())\n",
    "\n",
    "        # Temporal\n",
    "        temporal_decay = np.exp(-self.decay_rate * len(self.history))\n",
    "        state.temporal_weight = current_state * temporal_decay\n",
    "        \n",
    "        # Causal\n",
    "        prediction_accuracy = 1.0 - min(abs(prediction_error), 1.0)\n",
    "        state.causal_weight = prediction_accuracy\n",
    "        \n",
    "        # Novelty\n",
    "        novelty = abs(target_state - current_state)\n",
    "        if novelty > self.novelty_threshold:\n",
    "            state.novelty_weight = novelty\n",
    "        else:\n",
    "            state.novelty_weight *= (1 - self.decay_rate)\n",
    "        \n",
    "        self.states[neuron_id] = state\n",
    "        total_attention = state.compute_total()\n",
    "        self.history.append((neuron_id, total_attention))\n",
    "        if len(self.history) > self.memory_length:\n",
    "            self.history.pop(0)\n",
    "        \n",
    "        return total_attention\n",
    "\n",
    "class HebbianLayer:\n",
    "    def __init__(self, input_size, output_size, eta=0.01):\n",
    "        self.weights = np.random.randn(output_size, input_size) * 0.01\n",
    "        self.eta = eta\n",
    "\n",
    "    def forward(self, inputs: np.ndarray) -> np.ndarray:\n",
    "        return self.weights @ inputs\n",
    "\n",
    "    def hebbian_update(self, inputs: np.ndarray, outputs: np.ndarray):\n",
    "        delta_w = self.eta * np.outer(outputs, inputs)\n",
    "        self.weights += delta_w\n",
    "\n",
    "class DopamineModulator:\n",
    "    \"\"\"\n",
    "    Simple dopamine model that increases with strong input and decays over time.\n",
    "    Dopamine affects the neuron's effective time constant to slow decay when high.\n",
    "    \"\"\"\n",
    "    def __init__(self, increase_rate=0.05, decay_rate=0.01):\n",
    "        self.dopamine_level = 0.0\n",
    "        self.increase_rate = increase_rate\n",
    "        self.decay_rate = decay_rate\n",
    "\n",
    "    def update(self, input_strength: float):\n",
    "        # Increase dopamine if input is strong (above 0.5 for example)\n",
    "        if input_strength > 0.5:\n",
    "            self.dopamine_level += self.increase_rate * (input_strength - 0.5)\n",
    "        # Decay dopamine level\n",
    "        self.dopamine_level = max(0.0, self.dopamine_level - self.decay_rate)\n",
    "\n",
    "    def get_dopamine_modulation(self):\n",
    "        # Higher dopamine -> larger effective tau (less decay)\n",
    "        return 1.0 + self.dopamine_level\n",
    "\n",
    "class WeightedLTCNeuron:\n",
    "    def __init__(self, tau=1.0, num_inputs=3):\n",
    "        self.state = 0.0\n",
    "        self.base_tau = tau\n",
    "        self.num_inputs = num_inputs\n",
    "        self.weights = np.random.uniform(-0.5, 0.5, size=num_inputs)\n",
    "    \n",
    "    def update(self, inputs, dt=0.1, tau_mod=1.0, feedback=0.0):\n",
    "        # feedback is a recurrent input from another neuron\n",
    "        synaptic_input = np.dot(self.weights, inputs) + feedback\n",
    "        effective_tau = self.base_tau * tau_mod\n",
    "        dstate = (-self.state / effective_tau) + synaptic_input\n",
    "        self.state += dstate * dt\n",
    "        return self.state\n",
    "\n",
    "class SpecializedNeuron(WeightedLTCNeuron):\n",
    "    def __init__(self, tau=1.0, role=\"default\", num_inputs=3):\n",
    "        super().__init__(tau=tau, num_inputs=num_inputs)\n",
    "        self.role = role\n",
    "\n",
    "    def update(self, inputs, dt=0.1, tau_mod=1.0, feedback=0.0):\n",
    "        synaptic_input = np.dot(self.weights, inputs) + feedback\n",
    "        \n",
    "        if self.role == \"memory\":\n",
    "            # Slower decay baseline\n",
    "            effective_tau = self.base_tau * tau_mod * 1.5\n",
    "            dstate = (-self.state / effective_tau) + synaptic_input\n",
    "        elif self.role == \"inhibition\":\n",
    "            # Inhibit signals\n",
    "            synaptic_input = -synaptic_input * 0.5\n",
    "            effective_tau = self.base_tau * tau_mod\n",
    "            dstate = (-self.state / effective_tau) + synaptic_input\n",
    "        elif self.role == \"amplification\":\n",
    "            # Amplify signals\n",
    "            synaptic_input = synaptic_input * 1.5\n",
    "            effective_tau = self.base_tau * tau_mod\n",
    "            dstate = (-self.state / effective_tau) + synaptic_input\n",
    "        else:\n",
    "            # Default LTC behavior\n",
    "            effective_tau = self.base_tau * tau_mod\n",
    "            dstate = (-self.state / effective_tau) + synaptic_input\n",
    "        \n",
    "        self.state += dstate * dt\n",
    "        return self.state\n",
    "\n",
    "class LTCNeuronWithAttention:\n",
    "    def __init__(self, neuron_id: int, tau: float = 1.0):\n",
    "        self.id = neuron_id\n",
    "        self.tau = tau\n",
    "        self.state = 0.0\n",
    "        self.attention = CausalAttention()\n",
    "        self.last_prediction = 0.0\n",
    "        \n",
    "    def update(self, input_signal: float, dt: float) -> float:\n",
    "        prediction_error = input_signal - self.last_prediction\n",
    "        attention_value = self.attention.update(\n",
    "            neuron_id=self.id,\n",
    "            prediction_error=prediction_error,\n",
    "            current_state=self.state,\n",
    "            target_state=input_signal\n",
    "        )\n",
    "        effective_tau = self.tau * (1.0 - 0.3 * attention_value)\n",
    "        \n",
    "        d_state = (1.0/effective_tau) * ((input_signal * (1.0 + attention_value)) - self.state) * dt\n",
    "        self.state += d_state\n",
    "        self.last_prediction = self.state\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "\n",
    "class AttentiveNetworkWithHebbAndRoles:\n",
    "    def __init__(self, roles=None, input_size=3, eta=0.005, dopamine_increase_rate=0.05, dopamine_decay_rate=0.01):\n",
    "        if roles is None:\n",
    "            # Default roles: one memory, one inhibition, one amplification\n",
    "            roles = [\"memory\", \"inhibition\", \"amplification\"]\n",
    "        \n",
    "        self.neurons = [\n",
    "            SpecializedNeuron(tau=1.0+(0.2*i), role=roles[i % len(roles)], num_inputs=input_size)\n",
    "            for i in range(len(roles))\n",
    "        ]\n",
    "        \n",
    "        self.num_neurons = len(self.neurons)\n",
    "        self.hebb = HebbianLayer(input_size=input_size, output_size=self.num_neurons, eta=eta)\n",
    "        self.dopamine = DopamineModulator(increase_rate=dopamine_increase_rate, decay_rate=dopamine_decay_rate)\n",
    "        \n",
    "        self.state_history = []\n",
    "        self.input_history = []\n",
    "        self.time_steps = []\n",
    "        self.current_step = 0\n",
    "\n",
    "    def update_step(self, raw_inputs: List[float], dt=0.1):\n",
    "        inputs = np.array(raw_inputs)\n",
    "        \n",
    "        # Update dopamine based on input strength (e.g., mean of inputs)\n",
    "        input_strength = np.mean(inputs)\n",
    "        self.dopamine.update(input_strength)\n",
    "        tau_mod = self.dopamine.get_dopamine_modulation()\n",
    "        \n",
    "        # Hebbian forward pass\n",
    "        hebb_outputs = self.hebb.forward(inputs)\n",
    "        \n",
    "        # Simple recurrent feedback: let's feed the last neuron's state as feedback to the first neuron\n",
    "        feedback = self.neurons[-1].state * 0.1  # small feedback factor\n",
    "        \n",
    "        states = []\n",
    "        for i, neuron in enumerate(self.neurons):\n",
    "            fb = feedback if i == 0 else 0.0  # Only first neuron receives feedback from last neuron\n",
    "            s = neuron.update(hebb_outputs, dt, tau_mod=tau_mod, feedback=fb)\n",
    "            states.append(s)\n",
    "        \n",
    "        # Hebbian update\n",
    "        pre_activities = inputs\n",
    "        post_activities = np.array(states)\n",
    "        self.hebb.hebbian_update(pre_activities, post_activities)\n",
    "        \n",
    "        self.state_history.append(states)\n",
    "        self.input_history.append(raw_inputs)\n",
    "        self.time_steps.append(self.current_step)\n",
    "        self.current_step += 1\n",
    "        \n",
    "        return states\n",
    "\n",
    "    def plot_results(self):\n",
    "        states = np.array(self.state_history)\n",
    "        inputs = np.array(self.input_history)\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(2,1,figsize=(12,8))\n",
    "\n",
    "        # States\n",
    "        for i in range(self.num_neurons):\n",
    "            ax1.plot(self.time_steps, states[:, i], label=f'Neuron {i} ({self.neurons[i].role})')\n",
    "        ax1.set_title('Neuron States')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # Inputs\n",
    "        for i in range(inputs.shape[1]):\n",
    "            ax2.plot(self.time_steps, inputs[:, i], label=f'Input {i}')\n",
    "        ax2.set_title('Inputs')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_hebb_weights(self):\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.imshow(self.hebb.weights, aspect='auto', cmap='viridis')\n",
    "        plt.colorbar(label='Weight value')\n",
    "        plt.xlabel('Input Units')\n",
    "        plt.ylabel('Output Neurons')\n",
    "        plt.title('Hebbian Weights')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Time Step: 0\n",
      "Character: 'T' (ord=84, normalized=0.3294)\n",
      "dt: 0.0004s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0000\n",
      "Input to Hebbian layer: [0.32941176470588235, 0.16470588235294117, -0.03411764705882353]\n",
      "Hebbian outputs (to neurons): [-0.00251043 -0.00120517  0.00334201]\n",
      "Neuron 0 (memory): syn=-0.0023, tau=1.5000\n",
      "Neuron 0 (memory): old_state=0.0000, new_state=-0.0000, dstate=-0.0023\n",
      "Neuron 1 (inhibition): original syn=-0.0018, inhibited syn=0.0009, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0000, new_state=0.0000, dstate=0.0009\n",
      "Neuron 2 (amplification): original syn=0.0017, amplified syn=0.0026, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0000, new_state=0.0000, dstate=0.0026\n",
      "==================================================\n",
      "Time Step: 1\n",
      "Character: 'h' (ord=104, normalized=0.4078)\n",
      "dt: 0.2047s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0000\n",
      "Input to Hebbian layer: [0.40784313725490196, 0.20392156862745098, -0.01843137254901961]\n",
      "Hebbian outputs (to neurons): [-0.00295211 -0.00163146  0.00405424]\n",
      "Neuron 0 (memory): syn=-0.0027, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0000, new_state=-0.0005, dstate=-0.0027\n",
      "Neuron 1 (inhibition): original syn=-0.0022, inhibited syn=0.0011, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0000, new_state=0.0002, dstate=0.0011\n",
      "Neuron 2 (amplification): original syn=0.0021, amplified syn=0.0032, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0000, new_state=0.0007, dstate=0.0032\n",
      "==================================================\n",
      "Time Step: 2\n",
      "Character: 'e' (ord=101, normalized=0.3961)\n",
      "dt: 0.2122s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0001\n",
      "Input to Hebbian layer: [0.396078431372549, 0.1980392156862745, -0.0207843137254902]\n",
      "Hebbian outputs (to neurons): [-0.00288641 -0.00156729  0.00394807]\n",
      "Neuron 0 (memory): syn=-0.0026, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0005, new_state=-0.0010, dstate=-0.0022\n",
      "Neuron 1 (inhibition): original syn=-0.0022, inhibited syn=0.0011, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0002, new_state=0.0004, dstate=0.0009\n",
      "Neuron 2 (amplification): original syn=0.0021, amplified syn=0.0031, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0007, new_state=0.0012, dstate=0.0026\n",
      "==================================================\n",
      "Time Step: 3\n",
      "Character: ' ' (ord=32, normalized=0.1255)\n",
      "dt: 0.2159s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0001\n",
      "Input to Hebbian layer: [0.12549019607843137, 0.06274509803921569, -0.07490196078431373]\n",
      "Hebbian outputs (to neurons): [-1.36254998e-03 -9.66039967e-05  1.49080293e-03]\n",
      "Neuron 0 (memory): syn=-0.0010, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0010, new_state=-0.0011, dstate=-0.0003\n",
      "Neuron 1 (inhibition): original syn=-0.0008, inhibited syn=0.0004, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0004, new_state=0.0004, dstate=0.0001\n",
      "Neuron 2 (amplification): original syn=0.0007, amplified syn=0.0010, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0012, new_state=0.0012, dstate=0.0001\n",
      "==================================================\n",
      "Time Step: 4\n",
      "Character: 'q' (ord=113, normalized=0.4431)\n",
      "dt: 0.2152s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0001\n",
      "Input to Hebbian layer: [0.44313725490196076, 0.22156862745098038, -0.011372549019607847]\n",
      "Hebbian outputs (to neurons): [-0.00315299 -0.00182243  0.00437727]\n",
      "Neuron 0 (memory): syn=-0.0028, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0011, new_state=-0.0015, dstate=-0.0020\n",
      "Neuron 1 (inhibition): original syn=-0.0024, inhibited syn=0.0012, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0004, new_state=0.0006, dstate=0.0008\n",
      "Neuron 2 (amplification): original syn=0.0023, amplified syn=0.0035, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0012, new_state=0.0018, dstate=0.0026\n",
      "==================================================\n",
      "Time Step: 5\n",
      "Character: 'u' (ord=117, normalized=0.4588)\n",
      "dt: 0.2189s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0002\n",
      "Input to Hebbian layer: [0.4588235294117647, 0.22941176470588234, -0.008235294117647063]\n",
      "Hebbian outputs (to neurons): [-0.00324333 -0.00190689  0.0045221 ]\n",
      "Neuron 0 (memory): syn=-0.0028, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0015, new_state=-0.0019, dstate=-0.0018\n",
      "Neuron 1 (inhibition): original syn=-0.0025, inhibited syn=0.0012, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0006, new_state=0.0008, dstate=0.0007\n",
      "Neuron 2 (amplification): original syn=0.0024, amplified syn=0.0036, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0018, new_state=0.0023, dstate=0.0023\n",
      "==================================================\n",
      "Time Step: 6\n",
      "Character: 'i' (ord=105, normalized=0.4118)\n",
      "dt: 0.2155s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0002\n",
      "Input to Hebbian layer: [0.4117647058823529, 0.20588235294117646, -0.017647058823529415]\n",
      "Hebbian outputs (to neurons): [-0.00298016 -0.00165037  0.004097  ]\n",
      "Neuron 0 (memory): syn=-0.0025, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0019, new_state=-0.0022, dstate=-0.0012\n",
      "Neuron 1 (inhibition): original syn=-0.0022, inhibited syn=0.0011, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0008, new_state=0.0009, dstate=0.0005\n",
      "Neuron 2 (amplification): original syn=0.0022, amplified syn=0.0032, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0023, new_state=0.0027, dstate=0.0016\n",
      "==================================================\n",
      "Time Step: 7\n",
      "Character: 'c' (ord=99, normalized=0.3882)\n",
      "dt: 0.2166s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0003\n",
      "Input to Hebbian layer: [0.38823529411764707, 0.19411764705882353, -0.02235294117647059]\n",
      "Hebbian outputs (to neurons): [-0.00284949 -0.00152175  0.00388558]\n",
      "Neuron 0 (memory): syn=-0.0023, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0022, new_state=-0.0024, dstate=-0.0009\n",
      "Neuron 1 (inhibition): original syn=-0.0021, inhibited syn=0.0011, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0009, new_state=0.0009, dstate=0.0003\n",
      "Neuron 2 (amplification): original syn=0.0020, amplified syn=0.0031, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0027, new_state=0.0029, dstate=0.0012\n",
      "==================================================\n",
      "Time Step: 8\n",
      "Character: 'k' (ord=107, normalized=0.4196)\n",
      "dt: 0.2210s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0003\n",
      "Input to Hebbian layer: [0.4196078431372549, 0.20980392156862746, -0.01607843137254902]\n",
      "Hebbian outputs (to neurons): [-0.0030292  -0.00169105  0.00417419]\n",
      "Neuron 0 (memory): syn=-0.0025, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0024, new_state=-0.0026, dstate=-0.0009\n",
      "Neuron 1 (inhibition): original syn=-0.0023, inhibited syn=0.0011, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0009, new_state=0.0010, dstate=0.0004\n",
      "Neuron 2 (amplification): original syn=0.0022, amplified syn=0.0033, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0029, new_state=0.0032, dstate=0.0012\n",
      "==================================================\n",
      "Time Step: 9\n",
      "Character: ' ' (ord=32, normalized=0.1255)\n",
      "dt: 0.2463s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0003\n",
      "Input to Hebbian layer: [0.12549019607843137, 0.06274509803921569, -0.07490196078431373]\n",
      "Hebbian outputs (to neurons): [-1.36622647e-03 -9.51322910e-05  1.49528717e-03]\n",
      "Neuron 0 (memory): syn=-0.0008, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0026, new_state=-0.0023, dstate=0.0009\n",
      "Neuron 1 (inhibition): original syn=-0.0008, inhibited syn=0.0004, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0010, new_state=0.0009, dstate=-0.0004\n",
      "Neuron 2 (amplification): original syn=0.0007, amplified syn=0.0010, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0032, new_state=0.0029, dstate=-0.0013\n",
      "==================================================\n",
      "Time Step: 10\n",
      "Character: 'b' (ord=98, normalized=0.3843)\n",
      "dt: 0.2137s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0003\n",
      "Input to Hebbian layer: [0.3843137254901961, 0.19215686274509805, -0.02313725490196078]\n",
      "Hebbian outputs (to neurons): [-0.00283284 -0.00149827  0.0038567 ]\n",
      "Neuron 0 (memory): syn=-0.0023, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0023, new_state=-0.0025, dstate=-0.0007\n",
      "Neuron 1 (inhibition): original syn=-0.0021, inhibited syn=0.0011, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0009, new_state=0.0010, dstate=0.0003\n",
      "Neuron 2 (amplification): original syn=0.0020, amplified syn=0.0030, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0029, new_state=0.0031, dstate=0.0010\n",
      "==================================================\n",
      "Time Step: 11\n",
      "Character: 'r' (ord=114, normalized=0.4471)\n",
      "dt: 0.2156s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0003\n",
      "Input to Hebbian layer: [0.4470588235294118, 0.2235294117647059, -0.010588235294117643]\n",
      "Hebbian outputs (to neurons): [-0.00319099 -0.0018374   0.00443238]\n",
      "Neuron 0 (memory): syn=-0.0026, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0025, new_state=-0.0027, dstate=-0.0009\n",
      "Neuron 1 (inhibition): original syn=-0.0024, inhibited syn=0.0012, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0010, new_state=0.0011, dstate=0.0004\n",
      "Neuron 2 (amplification): original syn=0.0024, amplified syn=0.0035, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0031, new_state=0.0034, dstate=0.0013\n",
      "==================================================\n",
      "Time Step: 12\n",
      "Character: 'o' (ord=111, normalized=0.4353)\n",
      "dt: 0.2191s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0003\n",
      "Input to Hebbian layer: [0.43529411764705883, 0.21764705882352942, -0.012941176470588234]\n",
      "Hebbian outputs (to neurons): [-0.00312755 -0.00177236  0.00432907]\n",
      "Neuron 0 (memory): syn=-0.0025, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0027, new_state=-0.0029, dstate=-0.0007\n",
      "Neuron 1 (inhibition): original syn=-0.0024, inhibited syn=0.0012, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0011, new_state=0.0011, dstate=0.0003\n",
      "Neuron 2 (amplification): original syn=0.0023, amplified syn=0.0034, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0034, new_state=0.0036, dstate=0.0010\n",
      "==================================================\n",
      "Time Step: 13\n",
      "Character: 'w' (ord=119, normalized=0.4667)\n",
      "dt: 0.2149s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0004\n",
      "Input to Hebbian layer: [0.4666666666666667, 0.23333333333333334, -0.006666666666666665]\n",
      "Hebbian outputs (to neurons): [-0.00330933 -0.00194085  0.00462034]\n",
      "Neuron 0 (memory): syn=-0.0027, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0029, new_state=-0.0030, dstate=-0.0008\n",
      "Neuron 1 (inhibition): original syn=-0.0025, inhibited syn=0.0013, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0011, new_state=0.0012, dstate=0.0003\n",
      "Neuron 2 (amplification): original syn=0.0025, amplified syn=0.0037, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0036, new_state=0.0038, dstate=0.0011\n",
      "==================================================\n",
      "Time Step: 14\n",
      "Character: 'n' (ord=110, normalized=0.4314)\n",
      "dt: 0.2187s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0004\n",
      "Input to Hebbian layer: [0.43137254901960786, 0.21568627450980393, -0.013725490196078428]\n",
      "Hebbian outputs (to neurons): [-0.00311243 -0.00174829  0.00430227]\n",
      "Neuron 0 (memory): syn=-0.0025, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0030, new_state=-0.0031, dstate=-0.0004\n",
      "Neuron 1 (inhibition): original syn=-0.0023, inhibited syn=0.0012, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0012, new_state=0.0012, dstate=0.0002\n",
      "Neuron 2 (amplification): original syn=0.0023, amplified syn=0.0034, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0038, new_state=0.0040, dstate=0.0007\n",
      "==================================================\n",
      "Time Step: 15\n",
      "Character: ' ' (ord=32, normalized=0.1255)\n",
      "dt: 0.2230s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0004\n",
      "Input to Hebbian layer: [0.12549019607843137, 0.06274509803921569, -0.07490196078431373]\n",
      "Hebbian outputs (to neurons): [-1.37142097e-03 -9.30848642e-05  1.50181836e-03]\n",
      "Neuron 0 (memory): syn=-0.0007, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0031, new_state=-0.0028, dstate=0.0013\n",
      "Neuron 1 (inhibition): original syn=-0.0008, inhibited syn=0.0004, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0012, new_state=0.0011, dstate=-0.0006\n",
      "Neuron 2 (amplification): original syn=0.0007, amplified syn=0.0010, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0040, new_state=0.0036, dstate=-0.0018\n",
      "==================================================\n",
      "Time Step: 16\n",
      "Character: 'f' (ord=102, normalized=0.4000)\n",
      "dt: 0.2184s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0004\n",
      "Input to Hebbian layer: [0.4, 0.2, -0.019999999999999997]\n",
      "Hebbian outputs (to neurons): [-0.00293803 -0.00157688  0.00402034]\n",
      "Neuron 0 (memory): syn=-0.0023, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0028, new_state=-0.0029, dstate=-0.0004\n",
      "Neuron 1 (inhibition): original syn=-0.0022, inhibited syn=0.0011, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0011, new_state=0.0011, dstate=0.0002\n",
      "Neuron 2 (amplification): original syn=0.0021, amplified syn=0.0032, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0036, new_state=0.0037, dstate=0.0006\n",
      "==================================================\n",
      "Time Step: 17\n",
      "Character: 'o' (ord=111, normalized=0.4353)\n",
      "dt: 0.2168s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0004\n",
      "Input to Hebbian layer: [0.43529411764705883, 0.21764705882352942, -0.012941176470588234]\n",
      "Hebbian outputs (to neurons): [-0.00314257 -0.00176644  0.00434813]\n",
      "Neuron 0 (memory): syn=-0.0025, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0029, new_state=-0.0030, dstate=-0.0006\n",
      "Neuron 1 (inhibition): original syn=-0.0024, inhibited syn=0.0012, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0011, new_state=0.0012, dstate=0.0002\n",
      "Neuron 2 (amplification): original syn=0.0023, amplified syn=0.0034, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0037, new_state=0.0039, dstate=0.0008\n",
      "==================================================\n",
      "Time Step: 18\n",
      "Character: 'x' (ord=120, normalized=0.4706)\n",
      "dt: 0.2123s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0004\n",
      "Input to Hebbian layer: [0.47058823529411764, 0.23529411764705882, -0.005882352941176472]\n",
      "Hebbian outputs (to neurons): [-0.00334809 -0.00195561  0.00467717]\n",
      "Neuron 0 (memory): syn=-0.0027, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0030, new_state=-0.0032, dstate=-0.0007\n",
      "Neuron 1 (inhibition): original syn=-0.0026, inhibited syn=0.0013, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0012, new_state=0.0012, dstate=0.0003\n",
      "Neuron 2 (amplification): original syn=0.0025, amplified syn=0.0037, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0039, new_state=0.0041, dstate=0.0010\n",
      "==================================================\n",
      "Time Step: 19\n",
      "Character: ' ' (ord=32, normalized=0.1255)\n",
      "dt: 0.2164s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0004\n",
      "Input to Hebbian layer: [0.12549019607843137, 0.06274509803921569, -0.07490196078431373]\n",
      "Hebbian outputs (to neurons): [-1.37494020e-03 -9.17067287e-05  1.50631579e-03]\n",
      "Neuron 0 (memory): syn=-0.0007, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0032, new_state=-0.0029, dstate=0.0014\n",
      "Neuron 1 (inhibition): original syn=-0.0008, inhibited syn=0.0004, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0012, new_state=0.0011, dstate=-0.0006\n",
      "Neuron 2 (amplification): original syn=0.0007, amplified syn=0.0010, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0041, new_state=0.0037, dstate=-0.0019\n",
      "==================================================\n",
      "Time Step: 20\n",
      "Character: 'j' (ord=106, normalized=0.4157)\n",
      "dt: 0.2207s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0004\n",
      "Input to Hebbian layer: [0.41568627450980394, 0.20784313725490197, -0.01686274509803921]\n",
      "Hebbian outputs (to neurons): [-0.00303882 -0.00165726  0.00417868]\n",
      "Neuron 0 (memory): syn=-0.0024, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0029, new_state=-0.0030, dstate=-0.0005\n",
      "Neuron 1 (inhibition): original syn=-0.0023, inhibited syn=0.0011, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0011, new_state=0.0012, dstate=0.0002\n",
      "Neuron 2 (amplification): original syn=0.0022, amplified syn=0.0033, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0037, new_state=0.0038, dstate=0.0007\n",
      "==================================================\n",
      "Time Step: 21\n",
      "Character: 'u' (ord=117, normalized=0.4588)\n",
      "dt: 0.2243s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0004\n",
      "Input to Hebbian layer: [0.4588235294117647, 0.22941176470588234, -0.008235294117647063]\n",
      "Hebbian outputs (to neurons): [-0.00328966 -0.00188861  0.00458041]\n",
      "Neuron 0 (memory): syn=-0.0026, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0030, new_state=-0.0031, dstate=-0.0006\n",
      "Neuron 1 (inhibition): original syn=-0.0025, inhibited syn=0.0013, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0012, new_state=0.0012, dstate=0.0003\n",
      "Neuron 2 (amplification): original syn=0.0024, amplified syn=0.0036, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0038, new_state=0.0040, dstate=0.0009\n",
      "==================================================\n",
      "Time Step: 22\n",
      "Character: 'm' (ord=109, normalized=0.4275)\n",
      "dt: 0.2167s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0004\n",
      "Input to Hebbian layer: [0.42745098039215684, 0.21372549019607842, -0.014509803921568632]\n",
      "Hebbian outputs (to neurons): [-0.00311341 -0.00171794  0.00429618]\n",
      "Neuron 0 (memory): syn=-0.0024, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0031, new_state=-0.0032, dstate=-0.0004\n",
      "Neuron 1 (inhibition): original syn=-0.0023, inhibited syn=0.0012, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0012, new_state=0.0013, dstate=0.0002\n",
      "Neuron 2 (amplification): original syn=0.0023, amplified syn=0.0034, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0040, new_state=0.0041, dstate=0.0005\n",
      "==================================================\n",
      "Time Step: 23\n",
      "Character: 'p' (ord=112, normalized=0.4392)\n",
      "dt: 0.2191s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0004\n",
      "Input to Hebbian layer: [0.4392156862745098, 0.2196078431372549, -0.012156862745098041]\n",
      "Hebbian outputs (to neurons): [-0.0031848  -0.00177987  0.0044096 ]\n",
      "Neuron 0 (memory): syn=-0.0025, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0032, new_state=-0.0033, dstate=-0.0004\n",
      "Neuron 1 (inhibition): original syn=-0.0024, inhibited syn=0.0012, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0013, new_state=0.0013, dstate=0.0002\n",
      "Neuron 2 (amplification): original syn=0.0023, amplified syn=0.0035, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0041, new_state=0.0042, dstate=0.0005\n",
      "==================================================\n",
      "Time Step: 24\n",
      "Character: 's' (ord=115, normalized=0.4510)\n",
      "dt: 0.2206s, Dopamine Level: 0.0000, tau_mod: 1.0000\n",
      "Feedback applied to first neuron: 0.0004\n",
      "Input to Hebbian layer: [0.45098039215686275, 0.22549019607843138, -0.00980392156862745]\n",
      "Hebbian outputs (to neurons): [-0.0032566  -0.00184163  0.00452357]\n",
      "Neuron 0 (memory): syn=-0.0025, tau=1.5000\n",
      "Neuron 0 (memory): old_state=-0.0033, new_state=-0.0034, dstate=-0.0004\n",
      "Neuron 1 (inhibition): original syn=-0.0025, inhibited syn=0.0012, tau=1.2000\n",
      "Neuron 1 (inhibition): old_state=0.0013, new_state=0.0013, dstate=0.0002\n",
      "Neuron 2 (amplification): original syn=0.0024, amplified syn=0.0036, tau=1.4000\n",
      "Neuron 2 (amplification): old_state=0.0042, new_state=0.0044, dstate=0.0005\n"
     ]
    }
   ],
   "source": [
    "# Cell 3\n",
    "\n",
    "# Example input stream: a sequence of characters\n",
    "input_stream = list(\"The quick brown fox jumps\")\n",
    "\n",
    "# Initialize the updated network with roles, dopamine, and recurrence as before\n",
    "network = AttentiveNetworkWithHebbAndRoles(\n",
    "    roles=[\"memory\", \"inhibition\", \"amplification\"],\n",
    "    input_size=3, \n",
    "    eta=0.005,\n",
    "    dopamine_increase_rate=0.05,\n",
    "    dopamine_decay_rate=0.01\n",
    ")\n",
    "\n",
    "def char_to_inputs(ch):\n",
    "    val = ord(ch) / 255.0\n",
    "    return [val, val/2, (val-0.5)*0.2]\n",
    "\n",
    "states_over_time = []\n",
    "time_steps = []\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plt.ioff()\n",
    "\n",
    "last_time = time.time()\n",
    "\n",
    "for t, ch in enumerate(input_stream):\n",
    "    inp = char_to_inputs(ch)\n",
    "    current_time = time.time()\n",
    "    dt = current_time - last_time\n",
    "    last_time = current_time\n",
    "\n",
    "    # Before update, gather some internal info:\n",
    "    # We'll temporarily modify AttentiveNetworkWithHebbAndRoles to store intermediate vars for logging:\n",
    "    # (If you prefer not to modify the class, you can subclass or just print after calling update_step.)\n",
    "    # For this example, let's assume we add a method to return debug info after calling update_step.\n",
    "\n",
    "    # Manually replicate some logic from update_step to get intermediate steps for logging:\n",
    "    input_strength = np.mean(inp)\n",
    "    network.dopamine.update(input_strength)\n",
    "    tau_mod = network.dopamine.get_dopamine_modulation()\n",
    "    hebb_outputs = network.hebb.forward(np.array(inp))\n",
    "    feedback = network.neurons[-1].state * 0.1 if network.neurons else 0.0\n",
    "\n",
    "    # Print debugging info for this time slice\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Time Step: {t}\")\n",
    "    print(f\"Character: '{ch}' (ord={ord(ch)}, normalized={ord(ch)/255.0:.4f})\")\n",
    "    print(f\"dt: {dt:.4f}s, Dopamine Level: {network.dopamine.dopamine_level:.4f}, tau_mod: {tau_mod:.4f}\")\n",
    "    print(f\"Feedback applied to first neuron: {feedback:.4f}\")\n",
    "    print(\"Input to Hebbian layer:\", inp)\n",
    "    print(\"Hebbian outputs (to neurons):\", hebb_outputs)\n",
    "\n",
    "    # Now do the actual update_step as before\n",
    "    states = []\n",
    "    pre_activities = np.array(inp)\n",
    "    post_activities_list = []\n",
    "    # We'll replicate the internal loop of update_step for logging details:\n",
    "    for i, neuron in enumerate(network.neurons):\n",
    "        fb = feedback if i == 0 else 0.0\n",
    "\n",
    "        # Detailed logging for each neuron\n",
    "        synaptic_input = np.dot(neuron.weights, hebb_outputs) + fb\n",
    "        if neuron.role == \"memory\":\n",
    "            effective_tau = neuron.base_tau * tau_mod * 1.5\n",
    "            # memory role logic\n",
    "            dstate = (-neuron.state / effective_tau) + synaptic_input\n",
    "        elif neuron.role == \"inhibition\":\n",
    "            inh_syn = -synaptic_input * 0.5\n",
    "            effective_tau = neuron.base_tau * tau_mod\n",
    "            dstate = (-neuron.state / effective_tau) + inh_syn\n",
    "            # For logging, show transform:\n",
    "            print(f\"Neuron {i} ({neuron.role}): original syn={synaptic_input:.4f}, inhibited syn={inh_syn:.4f}, tau={effective_tau:.4f}\")\n",
    "        elif neuron.role == \"amplification\":\n",
    "            amp_syn = synaptic_input * 1.5\n",
    "            effective_tau = neuron.base_tau * tau_mod\n",
    "            dstate = (-neuron.state / effective_tau) + amp_syn\n",
    "            print(f\"Neuron {i} ({neuron.role}): original syn={synaptic_input:.4f}, amplified syn={amp_syn:.4f}, tau={effective_tau:.4f}\")\n",
    "        else:\n",
    "            effective_tau = neuron.base_tau * tau_mod\n",
    "            dstate = (-neuron.state / effective_tau) + synaptic_input\n",
    "        \n",
    "        # If memory role, also log details\n",
    "        if neuron.role == \"memory\":\n",
    "            print(f\"Neuron {i} ({neuron.role}): syn={synaptic_input:.4f}, tau={effective_tau:.4f}\")\n",
    "\n",
    "        # Update neuron state\n",
    "        old_state = neuron.state\n",
    "        neuron.state += dstate * dt\n",
    "        states.append(neuron.state)\n",
    "        post_activities_list.append(neuron.state)\n",
    "\n",
    "        print(f\"Neuron {i} ({neuron.role}): old_state={old_state:.4f}, new_state={neuron.state:.4f}, dstate={dstate:.4f}\")\n",
    "\n",
    "    # After updating neurons, perform Hebbian update\n",
    "    post_activities = np.array(post_activities_list)\n",
    "    network.hebb.hebbian_update(pre_activities, post_activities)\n",
    "    \n",
    "    # Record states\n",
    "    states_over_time.append(states)\n",
    "    time_steps.append(t)\n",
    "\n",
    "    # Plotting as before\n",
    "    #clear_output(wait=True)\n",
    "    \n",
    "    ax.clear()\n",
    "    states_array = np.array(states_over_time)\n",
    "    for i, neuron in enumerate(network.neurons):\n",
    "        ax.plot(time_steps, states_array[:, i], label=f'Neuron {i} ({neuron.role})')\n",
    "    \n",
    "    ax.set_title(f'Neuron States Over Time (last input: \"{ch}\")')\n",
    "    ax.set_xlabel('Time Step')\n",
    "    ax.set_ylabel('State')\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    \n",
    "    #display(fig)\n",
    "    time.sleep(0.2)\n",
    "\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
